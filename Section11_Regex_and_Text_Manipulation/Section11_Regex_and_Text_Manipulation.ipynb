{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Section11_Regex_and_Text_Manipulation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPTcoaycfc7oWTUT56/fVFP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"7s5LeA2W_rKd","executionInfo":{"status":"ok","timestamp":1638324479837,"user_tz":480,"elapsed":140,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["import numpy as np\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3xoMPLms83Y1"},"source":["# Section 11: Regex and Text Manipulation"]},{"cell_type":"markdown","metadata":{"id":"VUTyQTiw89z5"},"source":["Python and Pandas have a lot to offer in terms of extracting information from text and manipulation text. In this section we will cover#\n","* a detailed overview of Python string methods\n","* the Pandas `.str` family of methods\n","* advanced splits and replacements in Pandas\n","* hands-on introduction of RegEx\n","  * character sets, anchors, metasequences, quantifiers and more!\n","\n","We'll get some hands-on practice on this using a Boston marathon dataset"]},{"cell_type":"markdown","metadata":{"id":"gVIH3dIu_F1d"},"source":["## Our data: Boston Marathon Runners\n"]},{"cell_type":"markdown","metadata":{"id":"WyraaD00_eoU"},"source":["For this section we'll be working with a dataset for Boston marathon participants.\n","\n","https://andybek.com/pandas-marathon"]},{"cell_type":"code","metadata":{"id":"DDSaCxsf8rDT","executionInfo":{"status":"ok","timestamp":1638324479837,"user_tz":480,"elapsed":4,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston_url = 'https://andybek.com/pandas-marathon'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8zoJ6hK_n34","executionInfo":{"status":"ok","timestamp":1638324480272,"user_tz":480,"elapsed":438,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston = pd.read_csv(boston_url)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"I6CdwXXi_pqO","executionInfo":{"status":"ok","timestamp":1638324480272,"user_tz":480,"elapsed":9,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"9f3fd018-fab4-42b2-8e6b-c7e4acae0612"},"source":["boston.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Name  Age M/F  ... Overall Gender Years Ran\n","0   Kirui, Geoffrey    24   M  ...       1      1       NaN\n","1     Rupp, Galen      30   M  ...       2      2       NaN\n","2    Osako, Suguru     25   M  ...       3      3       NaN\n","3   Biwott, Shadrack   32   M  ...       4      4       NaN\n","4     Chebet, Wilson   31   M  ...       5      5      2015\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uhpe2LHO_3xs","executionInfo":{"status":"ok","timestamp":1638324480272,"user_tz":480,"elapsed":7,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"b3ebbfe1-ccd8-4277-9232-8da5167cdd4b"},"source":["boston.info"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method DataFrame.info of                     Name  Age M/F  ... Overall Gender  Years Ran\n","0       Kirui, Geoffrey    24   M  ...       1      1        NaN\n","1         Rupp, Galen      30   M  ...       2      2        NaN\n","2        Osako, Suguru     25   M  ...       3      3        NaN\n","3       Biwott, Shadrack   32   M  ...       4      4        NaN\n","4         Chebet, Wilson   31   M  ...       5      5       2015\n","..                   ...  ...  ..  ...     ...    ...        ...\n","995         Larosa, Mark   38   M  ...     996    940  2015:2016\n","996  Williamson, Jerry A   43   M  ...     997    941       2015\n","997      Mccue, Daniel T   40   M  ...     998    942        NaN\n","998         Larosa, John   35   M  ...     999    943        NaN\n","999       Sanchez, Sam R   35   M  ...    1000    944        NaN\n","\n","[1000 rows x 10 columns]>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"MERRgHkc_44V"},"source":["We hvae a dataset of 10 columns that include the Name, Age, and gender of eahc runner for the year 2017. Most of the fields are strings, including the \"Official Time\" which is text-based. This gives us plent of text data to play around with in this section."]},{"cell_type":"markdown","metadata":{"id":"6r3d0wAYABle"},"source":["## String Methods in Python"]},{"cell_type":"markdown","metadata":{"id":"O1QgPn0MBAmo"},"source":["We'll start by playing around with pure text in Python. We will cover the following concepts:\n","* `len`\n","* `center`\n","* `startswith` and `endswith`\n","* the `in` operator\n","* list comprehension with strings\n","\n","Link to common python string operations: https://docs.python.org/3/library/string.html"]},{"cell_type":"markdown","metadata":{"id":"KeMs9xEmBXVX"},"source":["Let's begin with a text string."]},{"cell_type":"code","metadata":{"id":"mw9uQ9qi_4Ta","executionInfo":{"status":"ok","timestamp":1638324480507,"user_tz":480,"elapsed":237,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["s = \"Welcome to the text manipulation section\""],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wDHPf29qBc5Q"},"source":["We can get the length of the string (number of characters)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y330dO6-BcaD","executionInfo":{"status":"ok","timestamp":1638324480507,"user_tz":480,"elapsed":36,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"f8db5d9d-6514-4b54-83e6-8a75f8653909"},"source":["len(s)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"HzfXDY7vBgk3"},"source":["The `center()` method creates a longer string that has the current string at the center and adds to both sides characters that we specify. The first value passed in to the function indicates the length of the final string, and the second value specifies that character(s) to be added to each side of the starting string to get the final string."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"47wJjXGnBgHi","executionInfo":{"status":"ok","timestamp":1638324480508,"user_tz":480,"elapsed":33,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"521e99a8-469b-4abd-846e-2dff8d2612f4"},"source":["s.center(100, '*')"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'******************************Welcome to the text manipulation section******************************'"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"3PKWr7-rBt0L"},"source":["Note that if your starting string is longer than the string you are attempting to build, you'll simply get the starting string back."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"uMrdg-qnBneg","executionInfo":{"status":"ok","timestamp":1638324480508,"user_tz":480,"elapsed":32,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"1ce0477b-2244-4b76-824b-2652c1bfcab6"},"source":["s.center(30, '*')"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome to the text manipulation section'"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"wqAn3m3tCIKM"},"source":["We can also check whether the string starts or ends with a given character or characters using `startswith()` and `endswith()`. \n","* Note that these methods are case-sensitive."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1a4YqSjACHbA","executionInfo":{"status":"ok","timestamp":1638324480508,"user_tz":480,"elapsed":31,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"364c6d7a-dcc8-42e8-8f18-acae03b73d98"},"source":["s.endswith('tion')"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NOHQvgdFCMik","executionInfo":{"status":"ok","timestamp":1638324480509,"user_tz":480,"elapsed":28,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"572ab2e3-0192-4011-e4d1-7da8a2b74d91"},"source":["s.startswith(\"Wel\")"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"tHfYAR_gCWO5"},"source":["To confirm that the string contains the given character or substring, Python does NOT have a dedicated \"contains\" or \"includes\" method. Instead, we check for inclusion using the `in` operator."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WoGE8Y83CQB3","executionInfo":{"status":"ok","timestamp":1638324480509,"user_tz":480,"elapsed":24,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"4858fb59-5c71-4e11-dff5-ad59c9e45d41"},"source":["'text manipulation' in s"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"euwXqIaaChke","executionInfo":{"status":"ok","timestamp":1638324480509,"user_tz":480,"elapsed":20,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"5ece029a-2096-437c-f8ed-ac9cbd8c1ba4"},"source":["'texted' in s"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"tOT0_V6bCmUP"},"source":["When analyzing datasets that contain text, we don't usually operate on individual strings. Instead, we take an operation and apply it to the entire collection of strings.\n","\n","One way to do this in Python is to apply text transforms within list comprehensions."]},{"cell_type":"code","metadata":{"id":"rHqWmrUsCjNz","executionInfo":{"status":"ok","timestamp":1638324480509,"user_tz":480,"elapsed":16,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["names = ['Alanah', 'Albion', 'Andrew', 'Brian']"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cP17poz1C0hO"},"source":["Suppose we want to find the lengths of all of the strings in this list. We could do this with list comprehension"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yD6Sh6YaCzqm","executionInfo":{"status":"ok","timestamp":1638324480510,"user_tz":480,"elapsed":16,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"a9173a77-ab65-4e2a-f6b0-2871df66b90d"},"source":["[len(name) for name in names]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[6, 6, 6, 5]"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"lPZKLgsGDDB_"},"source":["Similarly, we can call any function we want, including functions we define. For instance, we can check whether the names start with \"A\"."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fpxMckN4C5_V","executionInfo":{"status":"ok","timestamp":1638324480510,"user_tz":480,"elapsed":12,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"86fc0a28-09e1-42d7-abd6-e830f0854ec1"},"source":["[name.startswith('A') for name in names]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[True, True, True, False]"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"H3ILKOtQDRsB"},"source":["This approach is okay-looking, but it's actually quite fragile. For example if we had an invalid string or a missing value (which happens all of the time in real-world data), Python will thrown an error. \n","\n","Example:"]},{"cell_type":"code","metadata":{"id":"cPtqPvzeDP14","executionInfo":{"status":"ok","timestamp":1638324480510,"user_tz":480,"elapsed":8,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["names = ['Alanah', 'Albion', 'Andrew', np.NaN, 'Brian']"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"-NWcBG8KDfjo","executionInfo":{"status":"ok","timestamp":1638324480510,"user_tz":480,"elapsed":8,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["## Results in TypeError: object of type 'float' has no len()\n","# [len(name) for name in names]"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y4P8PvoGDmDE"},"source":["So we need some special logic to accommodate issues such as these. This is one aspect where Numpy and Pandas improve on the built-in Python capabilities. Pandas allows us to conduct large-scale text manipulation without having to worry about missing values."]},{"cell_type":"markdown","metadata":{"id":"kqbFFmyeHNuE"},"source":["## Vectorized String Operations in Pandas"]},{"cell_type":"markdown","metadata":{"id":"Ne2Nt0lJHSR6"},"source":["Pandas offers an extensive toolset for vectorized string operations on large sequences of text values. Many of the methods we discussed still apply, but the way we access them is a bit difference."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Mq4sluJoDf4D","executionInfo":{"status":"ok","timestamp":1638324480709,"user_tz":480,"elapsed":207,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"1076bd68-5690-4ea2-d317-6643fae71a0f"},"source":["boston.head()"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Name  Age M/F  ... Overall Gender Years Ran\n","0   Kirui, Geoffrey    24   M  ...       1      1       NaN\n","1     Rupp, Galen      30   M  ...       2      2       NaN\n","2    Osako, Suguru     25   M  ...       3      3       NaN\n","3   Biwott, Shadrack   32   M  ...       4      4       NaN\n","4     Chebet, Wilson   31   M  ...       5      5      2015\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"fa2IsY_2HbwS"},"source":["Suppose we want to find the name of each runner's name. Let's do it in Python first."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSAe65iEHfAj","executionInfo":{"status":"ok","timestamp":1638324480709,"user_tz":480,"elapsed":41,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"31ed7783-9540-4cad-d513-159bb7d8df8b"},"source":["len('Kirui, Geoffrey')"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"Hrz8DUZhHicK"},"source":["But if we get a hold of the entire name range as a Series and pass it to the `len()` function, we'll quickly see that it doesn't work. Instead, we simply get a single number indicating the number of values in the \"Name\" column."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SIsEspYHh83","executionInfo":{"status":"ok","timestamp":1638324480710,"user_tz":480,"elapsed":33,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"1567be4c-c3a9-47a7-8529-dfe8462370bc"},"source":["len(boston.Name)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"z_yl-flKH05t"},"source":["To get a series of lengths of names, we can use the `.str` family of methods. The `.str` is a common attribute that allows us to access vectorized string operations in Pandas. We can use it to, for example, perform vectorized calculations on the length of each name in the \"Name\" columns."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZ2bdyN-HuOm","executionInfo":{"status":"ok","timestamp":1638324480710,"user_tz":480,"elapsed":24,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"52c60497-cb14-448e-bb35-c941d6f98565"},"source":["boston.Name.str.len()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      17\n","1      14\n","2      15\n","3      16\n","4      14\n","       ..\n","995    12\n","996    19\n","997    15\n","998    12\n","999    14\n","Name: Name, Length: 1000, dtype: int64"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"PexxGEOeIJ1k"},"source":["The same goes for other functions."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieh7RLMgH7VF","executionInfo":{"status":"ok","timestamp":1638324480711,"user_tz":480,"elapsed":18,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"01d63730-8982-427a-fae4-569e7310b763"},"source":["boston.Name.str.startswith('A')"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","995    False\n","996    False\n","997    False\n","998    False\n","999    False\n","Name: Name, Length: 1000, dtype: bool"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"XOoCtmK-INw1"},"source":["For the most part, vectorized string methods in Pandas follow the same naming convention as built-in string methods. We'll see some exceptions later, but for the most part they are the same methods that we see in Python. The only difference is that they operate on the entire sequence at once and they exclude any missing values.\n","* https://docs.python.org/3/library/stdtypes.html#string-methods"]},{"cell_type":"markdown","metadata":{"id":"BR1raQQ5IUnO"},"source":["## Case Operations"]},{"cell_type":"markdown","metadata":{"id":"1KoQ9z2cIYtW"},"source":["There exist a family of methods that impact casing of text data. \n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.upper.html\n","* The page above also contains links to other string methods.\n","\n","For these examples let's focus on the \"City\" column"]},{"cell_type":"code","metadata":{"id":"uoT9RNAEIMT9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638324480711,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"fa7a13f0-0c03-417f-c211-17c377b10e5a"},"source":["boston.City"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           Keringet\n","1           Portland\n","2       Machida-City\n","3      Mammoth Lakes\n","4           Marakwet\n","           ...      \n","995    North Andover\n","996          Raleigh\n","997        Arlington\n","998          Danbury\n","999         Santa Fe\n","Name: City, Length: 1000, dtype: object"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"IFeDntC3IkLv"},"source":["The casing we see here is known as \"title case\", where the first letter of each word is capitalized. In both Python and Pandas it is applied using the `.title()` method."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9wabSDEBIjhk","executionInfo":{"status":"ok","timestamp":1638324480711,"user_tz":480,"elapsed":10,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"42591494-0a4e-4020-f53e-8c95f3e4fa28"},"source":["boston.City.str.title()"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           Keringet\n","1           Portland\n","2       Machida-City\n","3      Mammoth Lakes\n","4           Marakwet\n","           ...      \n","995    North Andover\n","996          Raleigh\n","997        Arlington\n","998          Danbury\n","999         Santa Fe\n","Name: City, Length: 1000, dtype: object"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"n4WuX6VkIu09"},"source":["This series was already title-cased, so the result is not particularly interesting (there was no change). So let's try another case operation. \n","\n","We can convert everything to upper case using the `.upper()` method."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IUgFPeM1Iten","executionInfo":{"status":"ok","timestamp":1638324480867,"user_tz":480,"elapsed":162,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"98593691-4a2f-48d3-86eb-8c3bfcb237a8"},"source":["boston.City.str.upper()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           KERINGET\n","1           PORTLAND\n","2       MACHIDA-CITY\n","3      MAMMOTH LAKES\n","4           MARAKWET\n","           ...      \n","995    NORTH ANDOVER\n","996          RALEIGH\n","997        ARLINGTON\n","998          DANBURY\n","999         SANTA FE\n","Name: City, Length: 1000, dtype: object"]},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"vE5iz8pSI7Lb"},"source":["A few other case methods include\n","* `lower()`\n","* `swapcase()` - reverses the current casing; upper becomes lower and lower becomes upper (instructor hasn't really found a great use for this method)\n","* `capitalize()` - capitalize the first letter of the *string* only (NOT the first letter of every word). All other letters are lower case"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7i6-THRKI6TK","executionInfo":{"status":"ok","timestamp":1638324480868,"user_tz":480,"elapsed":18,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"07e57ff0-f64c-4ec7-a381-68bdcfe4d136"},"source":["boston.City.str.lower()"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           keringet\n","1           portland\n","2       machida-city\n","3      mammoth lakes\n","4           marakwet\n","           ...      \n","995    north andover\n","996          raleigh\n","997        arlington\n","998          danbury\n","999         santa fe\n","Name: City, Length: 1000, dtype: object"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HW8WB_4lJEkb","executionInfo":{"status":"ok","timestamp":1638324480868,"user_tz":480,"elapsed":14,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"ac754f93-843c-4b88-ed19-aad6c02ce044"},"source":["boston.City.str.swapcase()"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           kERINGET\n","1           pORTLAND\n","2       mACHIDA-cITY\n","3      mAMMOTH lAKES\n","4           mARAKWET\n","           ...      \n","995    nORTH aNDOVER\n","996          rALEIGH\n","997        aRLINGTON\n","998          dANBURY\n","999         sANTA fE\n","Name: City, Length: 1000, dtype: object"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R4-I1pT8JGSE","executionInfo":{"status":"ok","timestamp":1638324480868,"user_tz":480,"elapsed":11,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"fbfa8193-01e9-4edb-d8c4-765d65a5c76b"},"source":["boston.City.str.capitalize()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           Keringet\n","1           Portland\n","2       Machida-city\n","3      Mammoth lakes\n","4           Marakwet\n","           ...      \n","995    North andover\n","996          Raleigh\n","997        Arlington\n","998          Danbury\n","999         Santa fe\n","Name: City, Length: 1000, dtype: object"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"cHx_N7SgK2UP"},"source":["## Finding Characters and Words: `str.find()` and `str.rfind()`"]},{"cell_type":"markdown","metadata":{"id":"-BeN77QbLN2R"},"source":["We'll begin with a review of the Python `find()` and `rfind()` function. Recall our simply string `s`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"2xgsu_bJJSyp","executionInfo":{"status":"ok","timestamp":1638324480868,"user_tz":480,"elapsed":8,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"09726872-5552-496d-c77e-975c9a6b0e1e"},"source":["s"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome to the text manipulation section'"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"oaBWYqkALWaZ"},"source":["Suppose we want to identify the exact position of the first lower-case \"x\" character in this string. To do this, we call the `find()` method on the string we are looking for and provide the search character.\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.find.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rdO1v1RJLUxq","executionInfo":{"status":"ok","timestamp":1638324480869,"user_tz":480,"elapsed":9,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"3eec4d95-1d39-47a8-e786-5586b80fdc48"},"source":["s.find('x')"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["17"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"ueKfVFNMLjUf"},"source":["We see that the first lower-case \"x\" is at index position 17 (the 18th letter of the string since Python is zero-indexed)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"dit5QPodLirs","executionInfo":{"status":"ok","timestamp":1638324481036,"user_tz":480,"elapsed":172,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"3468fb6c-f7c3-4f22-da0a-2b02ccc16222"},"source":["s[17]"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'x'"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"zgH1AIZxMnPx"},"source":["We can search for any sequence of characters that we want. For instance, let's look for a full substring \"text\". What returns is the position of the first character in that substring"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTKdzUFBMkYK","executionInfo":{"status":"ok","timestamp":1638324481036,"user_tz":480,"elapsed":27,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"9a9b23ac-a71f-403b-dc91-965d4a5a1694"},"source":["s.find('text')"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"JT32VpLTM4Hc"},"source":["If you ever provide a search string that does not exist in the queried string, the `find()` method will return -1.\n","\n","Returning now to Pandas, let's list the first few records to orient ourselves."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"LrfXduzdMw97","executionInfo":{"status":"ok","timestamp":1638324481036,"user_tz":480,"elapsed":24,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"46d9d8e7-5138-49e9-eccb-78310f3d5ce1"},"source":["boston.head()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Name  Age M/F  ... Overall Gender Years Ran\n","0   Kirui, Geoffrey    24   M  ...       1      1       NaN\n","1     Rupp, Galen      30   M  ...       2      2       NaN\n","2    Osako, Suguru     25   M  ...       3      3       NaN\n","3   Biwott, Shadrack   32   M  ...       4      4       NaN\n","4     Chebet, Wilson   31   M  ...       5      5      2015\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"EBloxXz1OOvo"},"source":["Here we'll pick the \"Name\" column and explore the number of top marathon runners have 'Andy' in their names. This can be easily achieved by applying the `find()` method to the entire sequence of names. Per usual, we will use the `.str` accessor and then apply the `find()` method."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m_dXSa2nONoY","executionInfo":{"status":"ok","timestamp":1638324481037,"user_tz":480,"elapsed":24,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"5e354969-a5d0-42c1-9828-018b35a1fdbf"},"source":["boston.Name.str.find('Andy')"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0     -1\n","1     -1\n","2     -1\n","3     -1\n","4     -1\n","      ..\n","995   -1\n","996   -1\n","997   -1\n","998   -1\n","999   -1\n","Name: Name, Length: 1000, dtype: int64"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"_Y32tBtMOwai"},"source":["What returns is a long sequence of integers, indicating the place in each name in which the substring \"Andy\" is located. Let's do a quick `value_counts()` analysis."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tMxi31YNOgG9","executionInfo":{"status":"ok","timestamp":1638324481037,"user_tz":480,"elapsed":20,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"1007d1c8-a7a1-4d43-ff11-79caf9622a03"},"source":["boston.Name.str.find('Andy').value_counts()"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1     998\n"," 12      1\n"," 8       1\n","Name: Name, dtype: int64"]},"metadata":{},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"N33y7DDGO6ZK"},"source":["There are actually two instances of someone having \"Andy\" in their name. Seems underrepresented. How about a name like \"James?\""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Auf_1u2JO3xF","executionInfo":{"status":"ok","timestamp":1638324481037,"user_tz":480,"elapsed":17,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"7f365834-bacb-4677-f8ad-9b3a65f292ef"},"source":["boston.Name.str.find('James').value_counts()"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["-1     988\n"," 10      3\n"," 8       3\n"," 9       2\n"," 7       2\n"," 12      1\n"," 6       1\n","Name: Name, dtype: int64"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"FSDp12vDPQj9"},"source":["The `find()` method performs a left-to-right search by default. If we start from the right instead, we'll get a different position integer returned. Let's illustrate this directionality with a new string."]},{"cell_type":"code","metadata":{"id":"ztEyLmGAPM1r","executionInfo":{"status":"ok","timestamp":1638324481037,"user_tz":480,"elapsed":13,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["p = 'pandas numpy numpy pandas'"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x7K9bMQPP57S"},"source":["Let's first try searching for \"pandas\""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vq2ZmspUP2UG","executionInfo":{"status":"ok","timestamp":1638324481038,"user_tz":480,"elapsed":13,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"852b1fd0-9145-415b-ad3b-9571490ebc66"},"source":["p.find('pandas')"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"gMVMWW7ZP-Oa"},"source":["We get zero, indicating that the first \"pandas\" substring instance begins at the 0th indexed position, as we expected. What if we want to start counting from the right side and determine that position in which \"pandas\" appears closest to the right? We do that using the `rfind()` method.\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.rfind.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjlXz3wJP9nO","executionInfo":{"status":"ok","timestamp":1638324481038,"user_tz":480,"elapsed":10,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"43a892c4-c72c-4b9b-d243-6a3497e575c9"},"source":["p.rfind('pandas')"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"1-lBWOqnQg2g"},"source":["Here the method indicated that, starting from the right side of the string, the first \"pandas\" occurrence is at position 19. We can verify this with a slice."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"pmvHoeiSQTTi","executionInfo":{"status":"ok","timestamp":1638324481198,"user_tz":480,"elapsed":166,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"6c72bb4b-396b-495d-a9c1-59cb8be5ba0d"},"source":["p[19:]"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'pandas'"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","metadata":{"id":"ERQMIRkgQ7ZT"},"source":["## Strips and Whitespace Methods"]},{"cell_type":"markdown","metadata":{"id":"LhIQV1QPRB7K"},"source":["**Whitespace** refers to characters that represent vertical or horizontal space, such as tab and newline characters. They are oftentimes not visible when a stirng is printed, but they do impact the spacing and positioning of the output.\n","\n","In this lecture we'll cover the following methods:\n","* `isspace()`\n","* `lstrip()`\n","* `rstrip()`\n","* `strip()`\n","\n","Descriptions of these methods can be find here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.strip.html\n","\n","To check whether a given character is a whitespace, we can use the Python method `isspace()`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zbQbzDHJQ23T","executionInfo":{"status":"ok","timestamp":1638324481199,"user_tz":480,"elapsed":21,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"8c75a2ab-6215-4c84-973b-1a5253e8ba7d"},"source":["' '.isspace()"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8p7Mb85RqUP","executionInfo":{"status":"ok","timestamp":1638324481199,"user_tz":480,"elapsed":18,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"982755bf-ec53-4596-e705-9129bbea1727"},"source":["'\\n'.isspace()"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":43}]},{"cell_type":"markdown","metadata":{"id":"DdkkE9dhRzWM"},"source":["Let's contain some sample strings that contain whitespace to work with for the rest of the section."]},{"cell_type":"code","metadata":{"id":"2tKtKqGnRwhs","executionInfo":{"status":"ok","timestamp":1638324481200,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["left_spaced = '     this is a pandas course'"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"E0WVdDKnR5wZ","executionInfo":{"status":"ok","timestamp":1638324481200,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["right_spaced = 'we cover plenty of Python too!      '"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"taDTSBICR9RG","executionInfo":{"status":"ok","timestamp":1638324481200,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["spaced = '    the name is: BOND \\t JAMES BOND \\n\\n'"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WJ7M6noXSCz-"},"source":["When printing the left_spaced string, the leading space will not be immediately obvious."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYtqqEksSCPi","executionInfo":{"status":"ok","timestamp":1638324481200,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"10433be8-69ed-45ac-c173-9a1640134115"},"source":["print(left_spaced)"],"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["     this is a pandas course\n"]}]},{"cell_type":"markdown","metadata":{"id":"dnJ1xqGfSIf6"},"source":["It's tough to see, but it's there and the whitespace contributes to the length of the overall string."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgUEuCu-SHbR","executionInfo":{"status":"ok","timestamp":1638324481201,"user_tz":480,"elapsed":12,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"d15eb65b-05bb-462a-e8d0-06b78158bb60"},"source":["print(spaced)"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["    the name is: BOND \t JAMES BOND \n","\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"ChGMGrRJTMNk"},"source":["Whitespace can be troublesome when working with text, which happens when gathering text from unstructured input, such as forums, comments, etc.\n","\n","Luckily, Python and Pandas offer a number of very useful methods to string whitespace from text. First up is `lstrip()`, which removes leading whitespace."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"kPC9_kUmSNAC","executionInfo":{"status":"ok","timestamp":1638324481201,"user_tz":480,"elapsed":8,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"64250d43-5c5d-42a8-e0f5-16a9bcbfdca7"},"source":["left_spaced.lstrip()"],"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'this is a pandas course'"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","metadata":{"id":"nEWvu2NATdjs"},"source":["`rstrip()` does the exact same thing, but on the right-hand side."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"qgWzX4lYTcro","executionInfo":{"status":"ok","timestamp":1638324481201,"user_tz":480,"elapsed":7,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"c05b47e0-ed62-4d56-ec88-435033bde552"},"source":["right_spaced.rstrip()"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'we cover plenty of Python too!'"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"PTQpBXfsTuTq"},"source":["The generic `strip()` method does the same thing but on both ends at the same time."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"-QyqHvFUTstl","executionInfo":{"status":"ok","timestamp":1638324481367,"user_tz":480,"elapsed":20,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"11f3af68-e5a1-42e6-8ed2-a55870a903e0"},"source":["spaced.strip()"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'the name is: BOND \\t JAMES BOND'"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","metadata":{"id":"kwlcYDFVTzpg"},"source":["Notice that the horizonatal tab character \"\\t\" is still there. Unfortunately there's no method that handles this character specifically. However, we'll hand this with replacement later on when we combine the replacement methods with regular expressions.\n","\n","Moving on to Pandas, let's again look at our dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"s_9JEEuYTyly","executionInfo":{"status":"ok","timestamp":1638324481367,"user_tz":480,"elapsed":19,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"6bff1fb4-f4de-4d1c-f2fc-fe0954deb06e"},"source":["boston.head()"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                Name  Age M/F  ... Overall Gender Years Ran\n","0   Kirui, Geoffrey    24   M  ...       1      1       NaN\n","1     Rupp, Galen      30   M  ...       2      2       NaN\n","2    Osako, Suguru     25   M  ...       3      3       NaN\n","3   Biwott, Shadrack   32   M  ...       4      4       NaN\n","4     Chebet, Wilson   31   M  ...       5      5      2015\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"dzo6qlqIUDTB"},"source":["Looking at our \"Name\" column, we see that some names have leading or trailing whitespace, for example the first two names on the list."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"q-hN-XdlUCnk","executionInfo":{"status":"ok","timestamp":1638324481367,"user_tz":480,"elapsed":19,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"8114de98-513c-43c9-d148-c86638a44560"},"source":["boston.Name.iloc[0]"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["' Kirui, Geoffrey '"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"jIIMxka6UIQC","executionInfo":{"status":"ok","timestamp":1638324481368,"user_tz":480,"elapsed":19,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"2b17daee-33b4-452b-d13b-899ba3eccacc"},"source":["boston.Name.iloc[1]"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Rupp, Galen   '"]},"metadata":{},"execution_count":54}]},{"cell_type":"markdown","metadata":{"id":"iuPGpWbuUQxb"},"source":["How do we apply the vectorized `strip()` method to this? It's the same syntax that we're familiar with."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HySdXQNFUQMw","executionInfo":{"status":"ok","timestamp":1638324481368,"user_tz":480,"elapsed":18,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"5f076b5c-424d-4c04-c5f9-c9d37d346673"},"source":["boston.Name.iloc[0:2].str.strip()"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    Kirui, Geoffrey\n","1        Rupp, Galen\n","Name: Name, dtype: object"]},"metadata":{},"execution_count":55}]},{"cell_type":"markdown","metadata":{"id":"zR9VEHO4Uc9h"},"source":["This has stripped all leading and trailing white space from the first two names. Let's go ahead and apply this to our entire sequence of names, and then assign the result back to the \"Name\" column."]},{"cell_type":"code","metadata":{"id":"f5vsGSzrUXZL","executionInfo":{"status":"ok","timestamp":1638324481368,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston.Name = boston.Name.str.strip()"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"eirwqF4rUqgQ","executionInfo":{"status":"ok","timestamp":1638324481368,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"0fa9bde8-db2a-41c1-9be0-5d5196d35813"},"source":["boston.head()"],"execution_count":57,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Overall Gender Years Ran\n","0   Kirui, Geoffrey   24   M  ...       1      1       NaN\n","1       Rupp, Galen   30   M  ...       2      2       NaN\n","2     Osako, Suguru   25   M  ...       3      3       NaN\n","3  Biwott, Shadrack   32   M  ...       4      4       NaN\n","4    Chebet, Wilson   31   M  ...       5      5      2015\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"Va5ai6t3UuR7"},"source":["Hard to tell if that did anything, let's verify that it worked by looking at the first name again. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"FYVzJtdIUrEM","executionInfo":{"status":"ok","timestamp":1638324481369,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"c700fd9f-658e-4324-983b-34a0ea9cd860"},"source":["boston.Name.iloc[0]"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Kirui, Geoffrey'"]},"metadata":{},"execution_count":58}]},{"cell_type":"markdown","metadata":{"id":"3Yp6SEn2U4Ek"},"source":["Sure enough, the leading whitespace is gone!"]},{"cell_type":"markdown","metadata":{"id":"G0IobljyJOSN"},"source":["## String Splitting and Concatenation: `split()`, `get()`, and `cat()`"]},{"cell_type":"markdown","metadata":{"id":"D6OGJEqKJSgA"},"source":["Splitting methods take a piece of text and break it down into smaller strings based on a break point that we specify.\n","\n","Recall our string from a few lectures ago, which we will call `split()` on.\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.split.html\n","\n","By default (when called without arguments), the method splits the string on **whitespace** and creates a list of strings consisting of the component \"words\" of the original string.\n","* Oftentimes this means splitting on single spaces, but any whitespace will be considered a split point by the method."]},{"cell_type":"code","metadata":{"id":"2L7QA1evU3YD","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1638324481369,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"3741b500-1b21-498f-8af5-5cf80c4d4339"},"source":["s"],"execution_count":59,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome to the text manipulation section'"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8cAeBHzbJjaK","executionInfo":{"status":"ok","timestamp":1638324481369,"user_tz":480,"elapsed":14,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"e94020aa-7379-44da-d5ea-2b539a106323"},"source":["s.split()"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Welcome', 'to', 'the', 'text', 'manipulation', 'section']"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","metadata":{"id":"jsH5MS9nKCly"},"source":["Consider the James Bond string from earlier. First we will attempt to split on any whitespace."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"CpRe1BPuJj9I","executionInfo":{"status":"ok","timestamp":1638324481369,"user_tz":480,"elapsed":10,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"4f136abb-25a4-431c-fcef-39f7422a434b"},"source":["spaced"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'    the name is: BOND \\t JAMES BOND \\n\\n'"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hog4j66zKFrF","executionInfo":{"status":"ok","timestamp":1638324481560,"user_tz":480,"elapsed":200,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"bc5cf948-6e62-45e3-f032-77beec9a6355"},"source":["spaced.split()"],"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['the', 'name', 'is:', 'BOND', 'JAMES', 'BOND']"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","metadata":{"id":"4Pr0Oa2jKPs5"},"source":["WHat if we try to split specifically by a single space?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qC6bfvyaKGSk","executionInfo":{"status":"ok","timestamp":1638324481560,"user_tz":480,"elapsed":45,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"41a5132b-d658-49fc-d62a-bc06585207bd"},"source":["spaced.split(' ')"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['', '', '', '', 'the', 'name', 'is:', 'BOND', '\\t', 'JAMES', 'BOND', '\\n\\n']"]},"metadata":{},"execution_count":63}]},{"cell_type":"markdown","metadata":{"id":"yxbHzNW0KTa6"},"source":["It is also worth mentioning that we can split a string on anything we want. For instance, we can split or `s` string on \"to\""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3blRzFgyKMOv","executionInfo":{"status":"ok","timestamp":1638324481560,"user_tz":480,"elapsed":39,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"af5819f2-ae7b-4d95-e987-e42e562e0ea8"},"source":["s.split('to')"],"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Welcome ', ' the text manipulation section']"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","metadata":{"id":"sGN7tP_jKhYt"},"source":["One last important note, as observed above, is that the string that is chosen as the split point is not included in the returned collection; it is always discarded.\n","\n","Now let's bring this over to Pandas and our dataframe."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"PoMIUXAKKb_3","executionInfo":{"status":"ok","timestamp":1638324481561,"user_tz":480,"elapsed":35,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"06eff84d-e470-4255-f0e8-a0166f065171"},"source":["boston.head()"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Overall Gender Years Ran\n","0   Kirui, Geoffrey   24   M  ...       1      1       NaN\n","1       Rupp, Galen   30   M  ...       2      2       NaN\n","2     Osako, Suguru   25   M  ...       3      3       NaN\n","3  Biwott, Shadrack   32   M  ...       4      4       NaN\n","4    Chebet, Wilson   31   M  ...       5      5      2015\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":65}]},{"cell_type":"markdown","metadata":{"id":"HYBGMxLUK0LY"},"source":["Suppose we need to introduce two new columns to our dataframe, one with runners' first names and another with runners' last names. Notice how every runner is identified by their last name, comma, space, first name. Thus, a good condidate for the split string is \", \". \n","\n","Let's try it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z96CII7KKzba","executionInfo":{"status":"ok","timestamp":1638324481561,"user_tz":480,"elapsed":35,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"e0cb977c-d1a7-4221-ec80-c94f15086a4c"},"source":["boston.Name.str.split(', ')"],"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0          [Kirui, Geoffrey]\n","1              [Rupp, Galen]\n","2            [Osako, Suguru]\n","3         [Biwott, Shadrack]\n","4           [Chebet, Wilson]\n","               ...          \n","995           [Larosa, Mark]\n","996    [Williamson, Jerry A]\n","997        [Mccue, Daniel T]\n","998           [Larosa, John]\n","999         [Sanchez, Sam R]\n","Name: Name, Length: 1000, dtype: object"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"8viG744rLLi8"},"source":["This returns a pandas series of Python lists - each runner's name was split on the \", \" and returned a list of the two component names.\n","\n","Now we need to get these first and last names in their own respective columns. How do we extract the first item for each of our records?\n","\n","One way to it is to chain on a special Pandas string method called `str.get()`, which is designed precisely for instances like this. Simply put. it extracts an element from each component at the specified location.\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.get.html\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8J4pNcLLI4A","executionInfo":{"status":"ok","timestamp":1638324481561,"user_tz":480,"elapsed":28,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"6535040a-bf9b-4f29-c5fb-32815f135b97"},"source":["boston.Name.str.split(', ').str.get(0)"],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0           Kirui\n","1            Rupp\n","2           Osako\n","3          Biwott\n","4          Chebet\n","          ...    \n","995        Larosa\n","996    Williamson\n","997         Mccue\n","998        Larosa\n","999       Sanchez\n","Name: Name, Length: 1000, dtype: object"]},"metadata":{},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"QtCyLG-2MGpO"},"source":["That gaveu s the last names. We can do the same for the first names."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"64LEgIt2L7RA","executionInfo":{"status":"ok","timestamp":1638324481562,"user_tz":480,"elapsed":22,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"50d3038a-ca86-496b-946f-f361fe8836fe"},"source":["boston.Name.str.split(', ').str.get(1)"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      Geoffrey\n","1         Galen\n","2        Suguru\n","3      Shadrack\n","4        Wilson\n","         ...   \n","995        Mark\n","996     Jerry A\n","997    Daniel T\n","998        John\n","999       Sam R\n","Name: Name, Length: 1000, dtype: object"]},"metadata":{},"execution_count":68}]},{"cell_type":"markdown","metadata":{"id":"5JfP2QU8MKBJ"},"source":["The only thing left to do now is to assign these names to their own columns in our dataframe."]},{"cell_type":"code","metadata":{"id":"kBSrOv50MJX3","executionInfo":{"status":"ok","timestamp":1638324481562,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston['First Name'] = boston.Name.str.split(', ').str.get(1)"],"execution_count":69,"outputs":[]},{"cell_type":"code","metadata":{"id":"HS_wLhgvMRoK","executionInfo":{"status":"ok","timestamp":1638324481562,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston['Last Name'] = boston.Name.str.split(', ').str.get(0)"],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Dv33UNAPMTNb","executionInfo":{"status":"ok","timestamp":1638324481562,"user_tz":480,"elapsed":14,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"dfe72001-30cb-4abd-f7de-8709f82561ae"},"source":["boston.head()"],"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>First Name</th>\n","      <th>Last Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Geoffrey</td>\n","      <td>Kirui</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>Galen</td>\n","      <td>Rupp</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>Suguru</td>\n","      <td>Osako</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>Shadrack</td>\n","      <td>Biwott</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","      <td>Wilson</td>\n","      <td>Chebet</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Years Ran First Name Last Name\n","0   Kirui, Geoffrey   24   M  ...       NaN   Geoffrey     Kirui\n","1       Rupp, Galen   30   M  ...       NaN      Galen      Rupp\n","2     Osako, Suguru   25   M  ...       NaN     Suguru     Osako\n","3  Biwott, Shadrack   32   M  ...       NaN   Shadrack    Biwott\n","4    Chebet, Wilson   31   M  ...      2015     Wilson    Chebet\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":71}]},{"cell_type":"markdown","metadata":{"id":"sRuAr3vjMxxb"},"source":["How would we do the opposite of this, and concatenate two strings from different columns together? \n","\n","Suppose we wanted to combine Age and Gender into a single column. We could do this using the `str.cat()` method (short for concatenate)\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.cat.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8PzhEJqfMTu2","executionInfo":{"status":"ok","timestamp":1638324481563,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"c79d90bc-89b1-4bf9-c673-e3962958d5a6"},"source":["boston['M/F'].str.cat(boston.Age.astype(str), sep = '_')"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      M_24\n","1      M_30\n","2      M_25\n","3      M_32\n","4      M_31\n","       ... \n","995    M_38\n","996    M_43\n","997    M_40\n","998    M_35\n","999    M_35\n","Name: M/F, Length: 1000, dtype: object"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"8IRQ7qCZNM_b","executionInfo":{"status":"ok","timestamp":1638324481745,"user_tz":480,"elapsed":192,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"dd0c16f3-2239-4d4a-cfc5-d2b4f22188df"},"source":["boston.head()"],"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>First Name</th>\n","      <th>Last Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Geoffrey</td>\n","      <td>Kirui</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>Galen</td>\n","      <td>Rupp</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>Suguru</td>\n","      <td>Osako</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>Shadrack</td>\n","      <td>Biwott</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","      <td>Wilson</td>\n","      <td>Chebet</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Years Ran First Name Last Name\n","0   Kirui, Geoffrey   24   M  ...       NaN   Geoffrey     Kirui\n","1       Rupp, Galen   30   M  ...       NaN      Galen      Rupp\n","2     Osako, Suguru   25   M  ...       NaN     Suguru     Osako\n","3  Biwott, Shadrack   32   M  ...       NaN   Shadrack    Biwott\n","4    Chebet, Wilson   31   M  ...      2015     Wilson    Chebet\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"YoH0_wggOQQw"},"source":["## More Split Parameters"]},{"cell_type":"markdown","metadata":{"id":"hkpwr12UOfoz"},"source":["In this lecture we'll cover additional parameters in the `split()` method.\n","\n","Let's start by dropping the \"First Name\" and \"Last Name\" columns that we created in the previous lecture, as we're about to discover a new way to create those columns."]},{"cell_type":"code","metadata":{"id":"HrA8osZDNSia","executionInfo":{"status":"ok","timestamp":1638324481745,"user_tz":480,"elapsed":21,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston.drop(labels = ['First Name', 'Last Name'], axis = 1, inplace = True)"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"BpWiNO9QOzZh","executionInfo":{"status":"ok","timestamp":1638324481746,"user_tz":480,"elapsed":21,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"9b9759f9-0aed-447a-fa9c-43e8868ec580"},"source":["boston.head()"],"execution_count":75,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Overall Gender Years Ran\n","0   Kirui, Geoffrey   24   M  ...       1      1       NaN\n","1       Rupp, Galen   30   M  ...       2      2       NaN\n","2     Osako, Suguru   25   M  ...       3      3       NaN\n","3  Biwott, Shadrack   32   M  ...       4      4       NaN\n","4    Chebet, Wilson   31   M  ...       5      5      2015\n","\n","[5 rows x 10 columns]"]},"metadata":{},"execution_count":75}]},{"cell_type":"markdown","metadata":{"id":"HRE8U0_HO6BY"},"source":["The first parameter we'll explore is `expand`. When set to True, the `split()` method returns a dataframe that has as many columns as the component strings were split into. Compare this to the behavior of `split()` without this parameter, where each name returned a list of substrings."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"8iibfbBqO5Px","executionInfo":{"status":"ok","timestamp":1638324481746,"user_tz":480,"elapsed":21,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"0d18408e-b384-410b-ee9f-9d0c0258e20c"},"source":["boston.Name.str.split(', ', expand = True)"],"execution_count":76,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Larosa</td>\n","      <td>Mark</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Williamson</td>\n","      <td>Jerry A</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Mccue</td>\n","      <td>Daniel T</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Larosa</td>\n","      <td>John</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Sanchez</td>\n","      <td>Sam R</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows  2 columns</p>\n","</div>"],"text/plain":["              0         1\n","0         Kirui  Geoffrey\n","1          Rupp     Galen\n","2         Osako    Suguru\n","3        Biwott  Shadrack\n","4        Chebet    Wilson\n","..          ...       ...\n","995      Larosa      Mark\n","996  Williamson   Jerry A\n","997       Mccue  Daniel T\n","998      Larosa      John\n","999     Sanchez     Sam R\n","\n","[1000 rows x 2 columns]"]},"metadata":{},"execution_count":76}]},{"cell_type":"markdown","metadata":{"id":"-AW9Jor9PQCx"},"source":["What happens if we exclude the split pattern altogether? What would happen then?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"H1YBBr9vPMQV","executionInfo":{"status":"ok","timestamp":1638324481746,"user_tz":480,"elapsed":20,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"989d96d0-5cf5-42cf-c03b-6c527f2acec6"},"source":["boston.Name.str.split(expand = True)"],"execution_count":77,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui,</td>\n","      <td>Geoffrey</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp,</td>\n","      <td>Galen</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako,</td>\n","      <td>Suguru</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott,</td>\n","      <td>Shadrack</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet,</td>\n","      <td>Wilson</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Larosa,</td>\n","      <td>Mark</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Williamson,</td>\n","      <td>Jerry</td>\n","      <td>A</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Mccue,</td>\n","      <td>Daniel</td>\n","      <td>T</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Larosa,</td>\n","      <td>John</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Sanchez,</td>\n","      <td>Sam</td>\n","      <td>R</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows  5 columns</p>\n","</div>"],"text/plain":["               0         1     2     3     4\n","0         Kirui,  Geoffrey  None  None  None\n","1          Rupp,     Galen  None  None  None\n","2         Osako,    Suguru  None  None  None\n","3        Biwott,  Shadrack  None  None  None\n","4        Chebet,    Wilson  None  None  None\n","..           ...       ...   ...   ...   ...\n","995      Larosa,      Mark  None  None  None\n","996  Williamson,     Jerry     A  None  None\n","997       Mccue,    Daniel     T  None  None\n","998      Larosa,      John  None  None  None\n","999     Sanchez,       Sam     R  None  None\n","\n","[1000 rows x 5 columns]"]},"metadata":{},"execution_count":77}]},{"cell_type":"markdown","metadata":{"id":"a2O7is_-PVU_"},"source":["In this case we get a five-column dataframe, the reason being that some runners have names with more than two substrings, and at least one runner has a name with 5 substrings that are split by a whitespace. Can we identify these long-named folks?\n","\n","One way we can do this is by running a `.count()` method on the columns (axis = 1), which returns the number of non-null columns. Anyone with more than 3 non-null columns has a three-component or longer name.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxkyRVmqPUlj","executionInfo":{"status":"ok","timestamp":1638324481746,"user_tz":480,"elapsed":19,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"3a15435a-f7de-45d5-e375-3288eac0115a"},"source":["boston.Name.str.split(expand = True).count(axis = 1)"],"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      2\n","1      2\n","2      2\n","3      2\n","4      2\n","      ..\n","995    2\n","996    3\n","997    3\n","998    2\n","999    3\n","Length: 1000, dtype: int64"]},"metadata":{},"execution_count":78}]},{"cell_type":"markdown","metadata":{"id":"npAGquaqQXgt"},"source":["How do we isolate people will, for instance, 5-component names? We can do this by setting a conditional to the count."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CTC_jUx2QFGk","executionInfo":{"status":"ok","timestamp":1638324481747,"user_tz":480,"elapsed":16,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"d52753cb-cb26-4250-d71e-c2c94ea3b505"},"source":["boston.Name.str.split(expand = True).count(axis = 1) == 5"],"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","995    False\n","996    False\n","997    False\n","998    False\n","999    False\n","Length: 1000, dtype: bool"]},"metadata":{},"execution_count":79}]},{"cell_type":"markdown","metadata":{"id":"kZgECP1FQh0D"},"source":["This returns a boolean mask, which we can then use as a selector to pass"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6D8gBqE9QhQm","executionInfo":{"status":"ok","timestamp":1638324481747,"user_tz":480,"elapsed":13,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"94561ca3-c8d8-49b3-cfe3-9ca91433bf5a"},"source":["boston.Name[boston.Name.str.split(expand = True).count(axis = 1) == 5]"],"execution_count":80,"outputs":[{"output_type":"execute_result","data":{"text/plain":["203    Cifuentes Fetiva, Miguel Angel Sr.\n","467      Martinez Solano, Juan Manuel Jr.\n","678        Melendez, Carlos Manuel M. Sr.\n","733        Castano Gonzalez, Angel U. Sr.\n","Name: Name, dtype: object"]},"metadata":{},"execution_count":80}]},{"cell_type":"markdown","metadata":{"id":"5wwUMpcvQpBA"},"source":["Thus, here are the folks who have long, five-component names.\n","\n","The `split()` method also has a parameter called `n`, which can be used to specify the number of substrings that is returned by the split."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"YB-xpJ1PQoWG","executionInfo":{"status":"ok","timestamp":1638324481747,"user_tz":480,"elapsed":9,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"4b17d060-1302-43d8-80ce-520191497ff6"},"source":["boston.Name.str.split(expand = True)"],"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui,</td>\n","      <td>Geoffrey</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp,</td>\n","      <td>Galen</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako,</td>\n","      <td>Suguru</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott,</td>\n","      <td>Shadrack</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet,</td>\n","      <td>Wilson</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Larosa,</td>\n","      <td>Mark</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Williamson,</td>\n","      <td>Jerry</td>\n","      <td>A</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Mccue,</td>\n","      <td>Daniel</td>\n","      <td>T</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Larosa,</td>\n","      <td>John</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Sanchez,</td>\n","      <td>Sam</td>\n","      <td>R</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows  5 columns</p>\n","</div>"],"text/plain":["               0         1     2     3     4\n","0         Kirui,  Geoffrey  None  None  None\n","1          Rupp,     Galen  None  None  None\n","2         Osako,    Suguru  None  None  None\n","3        Biwott,  Shadrack  None  None  None\n","4        Chebet,    Wilson  None  None  None\n","..           ...       ...   ...   ...   ...\n","995      Larosa,      Mark  None  None  None\n","996  Williamson,     Jerry     A  None  None\n","997       Mccue,    Daniel     T  None  None\n","998      Larosa,      John  None  None  None\n","999     Sanchez,       Sam     R  None  None\n","\n","[1000 rows x 5 columns]"]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","metadata":{"id":"bHkv6q1gRGC6"},"source":["By default, we get the maximum number of substrings. But if we want to change that, we can set the `n` parameter. For instance, if we set it to 2, we will get 3 columns."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"ZszRuu8FRDcx","executionInfo":{"status":"ok","timestamp":1638324481903,"user_tz":480,"elapsed":164,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"e94ea010-d812-4d1d-c287-c3cffba6f3df"},"source":["boston.Name.str.split(expand = True, n = 2)"],"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui,</td>\n","      <td>Geoffrey</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp,</td>\n","      <td>Galen</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako,</td>\n","      <td>Suguru</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott,</td>\n","      <td>Shadrack</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet,</td>\n","      <td>Wilson</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Larosa,</td>\n","      <td>Mark</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Williamson,</td>\n","      <td>Jerry</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Mccue,</td>\n","      <td>Daniel</td>\n","      <td>T</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Larosa,</td>\n","      <td>John</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Sanchez,</td>\n","      <td>Sam</td>\n","      <td>R</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows  3 columns</p>\n","</div>"],"text/plain":["               0         1     2\n","0         Kirui,  Geoffrey  None\n","1          Rupp,     Galen  None\n","2         Osako,    Suguru  None\n","3        Biwott,  Shadrack  None\n","4        Chebet,    Wilson  None\n","..           ...       ...   ...\n","995      Larosa,      Mark  None\n","996  Williamson,     Jerry     A\n","997       Mccue,    Daniel     T\n","998      Larosa,      John  None\n","999     Sanchez,       Sam     R\n","\n","[1000 rows x 3 columns]"]},"metadata":{},"execution_count":82}]},{"cell_type":"markdown","metadata":{"id":"pMyXiDbLRRNJ"},"source":["Let's return now to our ', ' split so that we get two-component names"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"MONyBZDdRPRM","executionInfo":{"status":"ok","timestamp":1638324481904,"user_tz":480,"elapsed":11,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"40c11837-6007-402b-c598-29a8e36901b6"},"source":["boston.Name.str.split(', ', expand = True)"],"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Larosa</td>\n","      <td>Mark</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Williamson</td>\n","      <td>Jerry A</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Mccue</td>\n","      <td>Daniel T</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Larosa</td>\n","      <td>John</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Sanchez</td>\n","      <td>Sam R</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows  2 columns</p>\n","</div>"],"text/plain":["              0         1\n","0         Kirui  Geoffrey\n","1          Rupp     Galen\n","2         Osako    Suguru\n","3        Biwott  Shadrack\n","4        Chebet    Wilson\n","..          ...       ...\n","995      Larosa      Mark\n","996  Williamson   Jerry A\n","997       Mccue  Daniel T\n","998      Larosa      John\n","999     Sanchez     Sam R\n","\n","[1000 rows x 2 columns]"]},"metadata":{},"execution_count":83}]},{"cell_type":"markdown","metadata":{"id":"1zs_4KTSRet_"},"source":["Now, how do we incorporate our columns in this dataframe into our original dataframe? \n","\n","We could use `join()` or `concat()`, but we can also use a *direct assignment* approach. This is also called *setting with enlargement* in Pandas because Pandas will check whether the columns exist in the dataframe, and if they do, the output will be overriden, and if they do not, the columns will be created anew."]},{"cell_type":"code","metadata":{"id":"4x7XVKPxRVOa","executionInfo":{"status":"ok","timestamp":1638324481904,"user_tz":480,"elapsed":11,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston[['Last Name', 'First Name']] = boston.Name.str.split(', ', expand = True)"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"gx6JpHRUSLfq","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638324481904,"user_tz":480,"elapsed":10,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"ad5a0583-55a9-4b19-ce62-3f5d276eda8a"},"source":["boston.head()"],"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Years Ran Last Name First Name\n","0   Kirui, Geoffrey   24   M  ...       NaN     Kirui   Geoffrey\n","1       Rupp, Galen   30   M  ...       NaN      Rupp      Galen\n","2     Osako, Suguru   25   M  ...       NaN     Osako     Suguru\n","3  Biwott, Shadrack   32   M  ...       NaN    Biwott   Shadrack\n","4    Chebet, Wilson   31   M  ...      2015    Chebet     Wilson\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":85}]},{"cell_type":"markdown","metadata":{"id":"l4UQ0HXjS0ER"},"source":["## Skill Challenge #1"]},{"cell_type":"markdown","metadata":{"id":"4vbnT6RQS2XW"},"source":["#### 1. How many runners in our dataset have \"James\" as a last name?"]},{"cell_type":"markdown","metadata":{"id":"iXejwb4BS8P3"},"source":["We've already done the hard work of adding \"Last Name\" as a unique column in our dataframe. All we really need to do now is query it for the name \"James\", which we can do using the `loc[]` indexer."]},{"cell_type":"code","metadata":{"id":"SDLzZgT2SMNU","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1638324481905,"user_tz":480,"elapsed":11,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"9f216b94-b39a-4850-a202-452ff373fe39"},"source":["boston.loc[boston['Last Name'] == \"James\"]"],"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [Name, Age, M/F, City, State, Country, Official Time, Overall, Gender, Years Ran, Last Name, First Name]\n","Index: []"]},"metadata":{},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"w1aqQkVnTMDf"},"source":["It looks like there are no runners with the last name of James. Do do this more computationally, we can simply perform a `count()` on the result."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-l8MUYpTK_N","executionInfo":{"status":"ok","timestamp":1638324481905,"user_tz":480,"elapsed":10,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"6530d4f9-13b2-4251-cfc0-022356baffff"},"source":["boston.loc[boston['Last Name'] == \"James\"].count()"],"execution_count":87,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Name             0\n","Age              0\n","M/F              0\n","City             0\n","State            0\n","Country          0\n","Official Time    0\n","Overall          0\n","Gender           0\n","Years Ran        0\n","Last Name        0\n","First Name       0\n","dtype: int64"]},"metadata":{},"execution_count":87}]},{"cell_type":"markdown","metadata":{"id":"SlfFTO4yWK3h"},"source":["Do any runners have the First Name of James? Let's find out. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"5Wj5jSiMWkJA","executionInfo":{"status":"ok","timestamp":1638324482088,"user_tz":480,"elapsed":189,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"23d3dda3-1ffd-4960-df81-ee4b8b612cf2"},"source":["boston.loc[boston['First Name'] == \"James\"]"],"execution_count":88,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>243</th>\n","      <td>Lloyd, James</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>San Diego</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:42:38</td>\n","      <td>244</td>\n","      <td>220</td>\n","      <td>2016</td>\n","      <td>Lloyd</td>\n","      <td>James</td>\n","    </tr>\n","    <tr>\n","      <th>574</th>\n","      <td>Onigkeit, James</td>\n","      <td>49</td>\n","      <td>M</td>\n","      <td>Rochester</td>\n","      <td>MN</td>\n","      <td>USA</td>\n","      <td>2:49:48</td>\n","      <td>575</td>\n","      <td>537</td>\n","      <td>2016</td>\n","      <td>Onigkeit</td>\n","      <td>James</td>\n","    </tr>\n","    <tr>\n","      <th>650</th>\n","      <td>O'Sullivan, James</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Arvada</td>\n","      <td>CO</td>\n","      <td>USA</td>\n","      <td>2:51:15</td>\n","      <td>651</td>\n","      <td>611</td>\n","      <td>2016</td>\n","      <td>O'Sullivan</td>\n","      <td>James</td>\n","    </tr>\n","    <tr>\n","      <th>923</th>\n","      <td>Baek, James</td>\n","      <td>23</td>\n","      <td>M</td>\n","      <td>Indianapolis</td>\n","      <td>IN</td>\n","      <td>USA</td>\n","      <td>2:55:12</td>\n","      <td>924</td>\n","      <td>873</td>\n","      <td>2016</td>\n","      <td>Baek</td>\n","      <td>James</td>\n","    </tr>\n","    <tr>\n","      <th>976</th>\n","      <td>Blowers, James</td>\n","      <td>45</td>\n","      <td>M</td>\n","      <td>Cary</td>\n","      <td>NC</td>\n","      <td>USA</td>\n","      <td>2:55:57</td>\n","      <td>977</td>\n","      <td>922</td>\n","      <td>NaN</td>\n","      <td>Blowers</td>\n","      <td>James</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Name  Age M/F  ... Years Ran   Last Name First Name\n","243       Lloyd, James   24   M  ...      2016       Lloyd      James\n","574    Onigkeit, James   49   M  ...      2016    Onigkeit      James\n","650  O'Sullivan, James   32   M  ...      2016  O'Sullivan      James\n","923        Baek, James   23   M  ...      2016        Baek      James\n","976     Blowers, James   45   M  ...       NaN     Blowers      James\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":88}]},{"cell_type":"markdown","metadata":{"id":"D41Cwd6LWm3n"},"source":["Yes, it appears that five runners have the first name \"James\"."]},{"cell_type":"markdown","metadata":{"id":"jUqYdzRETjRU"},"source":["#### 2. Split all of the \"City\" names in the dataset by the hyphen character, and create a dataframe containing each split component of the split name. Assign this dataframe to the variable `city_parts`."]},{"cell_type":"markdown","metadata":{"id":"aZqKMOmuTvXN"},"source":["We'll accomplish this using the `str.split()` method, passing in a hyphen as the split string and setting `expand` to `True`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"UyQJXoRSTS0i","executionInfo":{"status":"ok","timestamp":1638324482089,"user_tz":480,"elapsed":22,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"eb67f620-0a7e-4244-d857-f44fa88db191"},"source":["boston.City.str.split('-', expand = True)"],"execution_count":89,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Keringet</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Portland</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Machida</td>\n","      <td>City</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mammoth Lakes</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Marakwet</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>North Andover</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Raleigh</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Arlington</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Danbury</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Santa Fe</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows  4 columns</p>\n","</div>"],"text/plain":["                 0     1     2     3\n","0         Keringet  None  None  None\n","1         Portland  None  None  None\n","2          Machida  City  None  None\n","3    Mammoth Lakes  None  None  None\n","4         Marakwet  None  None  None\n","..             ...   ...   ...   ...\n","995  North Andover  None  None  None\n","996        Raleigh  None  None  None\n","997      Arlington  None  None  None\n","998        Danbury  None  None  None\n","999       Santa Fe  None  None  None\n","\n","[1000 rows x 4 columns]"]},"metadata":{},"execution_count":89}]},{"cell_type":"markdown","metadata":{"id":"PBcLZXSOUAcS"},"source":["Let's assign this to the variable as required by the prompt."]},{"cell_type":"code","metadata":{"id":"J4q248oCT7bm","executionInfo":{"status":"ok","timestamp":1638324482089,"user_tz":480,"elapsed":21,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["city_parts = boston.City.str.split('-', expand = True)"],"execution_count":90,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vGBIDhIcUE7Y"},"source":["#### 3. Determine the number of cities in the `boston` dataframe that have more than 1 component, and identify those cities."]},{"cell_type":"markdown","metadata":{"id":"AmP4FOjMUQdR"},"source":["Let's start by querying our `city_parts` variable with a conditional, where we want to identify cities that have more than one component in their name."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fh0MiXAsUEhu","executionInfo":{"status":"ok","timestamp":1638324482090,"user_tz":480,"elapsed":22,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"d8187be5-cea3-4533-d56b-49f9716ebc34"},"source":["city_parts.count(axis = 1) > 1"],"execution_count":91,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      False\n","1      False\n","2       True\n","3      False\n","4      False\n","       ...  \n","995    False\n","996    False\n","997    False\n","998    False\n","999    False\n","Length: 1000, dtype: bool"]},"metadata":{},"execution_count":91}]},{"cell_type":"markdown","metadata":{"id":"cddVK-sdUlSg"},"source":["With this boolean mask in hand, we can now select the cities that have compound names (at least when separated by hyphens). We can do this selection either from `city_parts` or from `boston`. Both approaches are shown below."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"nESKNPCSUkwv","executionInfo":{"status":"ok","timestamp":1638324482090,"user_tz":480,"elapsed":17,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"492a136a-3d35-4cb7-d6d2-ed7de55498ed"},"source":["city_parts[city_parts.count(axis = 1) > 1]"],"execution_count":92,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>Machida</td>\n","      <td>City</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>Sao Paulo</td>\n","      <td>Sp</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>188</th>\n","      <td>Baie</td>\n","      <td>St</td>\n","      <td>Paul</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>201</th>\n","      <td>Houghton</td>\n","      <td>Le</td>\n","      <td>Spring</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>371</th>\n","      <td>Boulogne</td>\n","      <td>Billancourt</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>420</th>\n","      <td>Mont</td>\n","      <td>Royal</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>585</th>\n","      <td>Gif</td>\n","      <td>Sur</td>\n","      <td>Yvette</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>615</th>\n","      <td>Fossambault</td>\n","      <td>Sur</td>\n","      <td>Le</td>\n","      <td>Lac</td>\n","    </tr>\n","    <tr>\n","      <th>724</th>\n","      <td>Wiesbaden</td>\n","      <td>Breckenheim</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>727</th>\n","      <td>Saint</td>\n","      <td>Tite</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>794</th>\n","      <td>Marica</td>\n","      <td>Rj</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>820</th>\n","      <td>Sainte</td>\n","      <td>Catherine</td>\n","      <td>De</td>\n","      <td>Hatley</td>\n","    </tr>\n","    <tr>\n","      <th>830</th>\n","      <td>Pont</td>\n","      <td>Rouge</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               0            1       2       3\n","2        Machida         City    None    None\n","35    Sao Paulo            Sp    None    None\n","188         Baie           St    Paul    None\n","201     Houghton           Le  Spring    None\n","371     Boulogne  Billancourt    None    None\n","420         Mont        Royal    None    None\n","585          Gif          Sur  Yvette    None\n","615  Fossambault          Sur      Le     Lac\n","724    Wiesbaden  Breckenheim    None    None\n","727        Saint         Tite    None    None\n","794      Marica            Rj    None    None\n","820       Sainte    Catherine      De  Hatley\n","830         Pont        Rouge    None    None"]},"metadata":{},"execution_count":92}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9aZiYlO4UyaM","executionInfo":{"status":"ok","timestamp":1638324482091,"user_tz":480,"elapsed":17,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"2d8aa46f-8cc3-4637-edf6-3538a65f16a5"},"source":["boston[city_parts.count(axis = 1) > 1]['City']"],"execution_count":93,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2                    Machida-City\n","35                 Sao Paulo - Sp\n","188                  Baie-St-Paul\n","201            Houghton-Le-Spring\n","371          Boulogne-Billancourt\n","420                    Mont-Royal\n","585                Gif-Sur-Yvette\n","615        Fossambault-Sur-Le-Lac\n","724         Wiesbaden-Breckenheim\n","727                    Saint-Tite\n","794                   Marica - Rj\n","820    Sainte-Catherine-De-Hatley\n","830                    Pont-Rouge\n","Name: City, dtype: object"]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","metadata":{"id":"Go4f_BEqkUjE"},"source":["## Slicing Substrings with `str.slice()`"]},{"cell_type":"markdown","metadata":{"id":"GsU4BkJDk8M2"},"source":["Let's talk about a new topic, which is extraction of slices of text from an existing string. We'll first do this on a single string in Python.\n","\n","Consider our introductory string:"]},{"cell_type":"code","metadata":{"id":"SBUdsS6SUzvZ","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1638324482091,"user_tz":480,"elapsed":13,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"112bca5c-05c4-4e89-e676-a95eb71c1a22"},"source":["s"],"execution_count":94,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome to the text manipulation section'"]},"metadata":{},"execution_count":94}]},{"cell_type":"markdown","metadata":{"id":"rUooMAI9lHp6"},"source":["If we want to extract a particular substring, we use the `str.slice()` method. We indicate where the slice should begin (defaults at 0), where it should end, and the step size (defaults at 1).\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.slice.html\n","\n","Suppose we want to extract the substring \"Welcome\". We can call the `slice()` method within selection brackets on the string."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"mfurV9hplG44","executionInfo":{"status":"ok","timestamp":1638324482092,"user_tz":480,"elapsed":13,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"a9900896-f704-4453-fb5e-618f09dd87a8"},"source":["s[slice(0, 7, 1)]"],"execution_count":95,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome'"]},"metadata":{},"execution_count":95}]},{"cell_type":"markdown","metadata":{"id":"xaNgOY1DllKm"},"source":["This slice syntax is typically not used explicity, but rather the colon-separated attributes at used with square bracketing instead. This is faster and easier to implement. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VSuRjgEvlW0B","executionInfo":{"status":"ok","timestamp":1638324482092,"user_tz":480,"elapsed":12,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"44d9d0f4-4acd-4451-941e-85a32182c779"},"source":["s[0:7:1]"],"execution_count":96,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome'"]},"metadata":{},"execution_count":96}]},{"cell_type":"markdown","metadata":{"id":"hfwOLitNmGTn"},"source":["Let's switch over to Pandas, where the string slice behavior is very similar to Python. Consider our `boston` dataframe once again"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"_W3zsCdYmAnw","executionInfo":{"status":"ok","timestamp":1638324482279,"user_tz":480,"elapsed":199,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"60efa0a0-1516-4e9a-9f81-2401fb3117bd"},"source":["boston.head()"],"execution_count":97,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Years Ran Last Name First Name\n","0   Kirui, Geoffrey   24   M  ...       NaN     Kirui   Geoffrey\n","1       Rupp, Galen   30   M  ...       NaN      Rupp      Galen\n","2     Osako, Suguru   25   M  ...       NaN     Osako     Suguru\n","3  Biwott, Shadrack   32   M  ...       NaN    Biwott   Shadrack\n","4    Chebet, Wilson   31   M  ...      2015    Chebet     Wilson\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":97}]},{"cell_type":"markdown","metadata":{"id":"QOI0bUx3mOrL"},"source":["Suppose we wanted to switch our three-character country codes to two-character codes, all we need to do is apply `str.slice()` to the \"Country\" column."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c-1jQfYqmOAj","executionInfo":{"status":"ok","timestamp":1638324482280,"user_tz":480,"elapsed":31,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"63e0785b-7d52-4968-ba7b-42dcf00ec9b6"},"source":["boston.Country.str.slice(0, 2, 1)"],"execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      KE\n","1      US\n","2      JP\n","3      US\n","4      KE\n","       ..\n","995    US\n","996    US\n","997    US\n","998    US\n","999    US\n","Name: Country, Length: 1000, dtype: object"]},"metadata":{},"execution_count":98}]},{"cell_type":"markdown","metadata":{"id":"qjxU5py3mayD"},"source":["We can also apply the slice method in the *reverse direction* from right to left by using negative indices. For instance, to get the same country codes but slice the last two characters instead (won't really make sense), we can do the following (note we are using the keyword arguments here):\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sOUnoJgEmZOV","executionInfo":{"status":"ok","timestamp":1638324482280,"user_tz":480,"elapsed":25,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"e04f03e5-7c6c-43c5-a226-49a09d22184f"},"source":["boston.Country.str.slice(start = -2, stop = None, step = 1)"],"execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      EN\n","1      SA\n","2      PN\n","3      SA\n","4      EN\n","       ..\n","995    SA\n","996    SA\n","997    SA\n","998    SA\n","999    SA\n","Name: Country, Length: 1000, dtype: object"]},"metadata":{},"execution_count":99}]},{"cell_type":"markdown","metadata":{"id":"tzLfQspom_2I"},"source":["Excellent! This gives us the last two characters of each three-character country code. This is the foundation is defining slices in terms of start, stop, and step, and is similar in both Python and Pandas. But with Pandas we get the added benefit of vectorized operations on entire series."]},{"cell_type":"markdown","metadata":{"id":"p0zVyGt9nLLN"},"source":["## Masking with String Methods: `str.match()` and `str.contains()`"]},{"cell_type":"markdown","metadata":{"id":"uGNLJpd0nVfR"},"source":["In Pandas, many string methods are very useful for quickly filtering and searching for data. One of the most \"Pandorial\" ways to go about this is using boolean masks. As a refresher, \n","* We first creates a series of booleans\n","* We then pass that series using brackets or a `loc[]` indexer to select from a dataframe or series\n","\n","Suppose we wanted to select all Italian runners from our `boston` dataframe."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"NCnh6LTFmy7a","executionInfo":{"status":"ok","timestamp":1638324482280,"user_tz":480,"elapsed":20,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"093797ab-8dbd-462e-92da-1fe3ab2f6410"},"source":["boston.head()"],"execution_count":100,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Years Ran Last Name First Name\n","0   Kirui, Geoffrey   24   M  ...       NaN     Kirui   Geoffrey\n","1       Rupp, Galen   30   M  ...       NaN      Rupp      Galen\n","2     Osako, Suguru   25   M  ...       NaN     Osako     Suguru\n","3  Biwott, Shadrack   32   M  ...       NaN    Biwott   Shadrack\n","4    Chebet, Wilson   31   M  ...      2015    Chebet     Wilson\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":100}]},{"cell_type":"markdown","metadata":{"id":"dGE_lINdnuya"},"source":["Let's start by creating a boolean series on the \"Country\" column. We can do this by boolean logic."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKKKfoJwnt3u","executionInfo":{"status":"ok","timestamp":1638324482281,"user_tz":480,"elapsed":20,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"b8266c88-11a8-4c2b-dda0-6b08ce55f46c"},"source":["boston.Country == 'ITA'"],"execution_count":101,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","995    False\n","996    False\n","997    False\n","998    False\n","999    False\n","Name: Country, Length: 1000, dtype: bool"]},"metadata":{},"execution_count":101}]},{"cell_type":"markdown","metadata":{"id":"t3gzVodln13Y"},"source":["We can also do this by using the Pandas `str.match()` method.\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.match.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"acVxWvI_nyH0","executionInfo":{"status":"ok","timestamp":1638324482281,"user_tz":480,"elapsed":17,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"0c0369d0-2e97-4426-96e6-94dba8ef3a08"},"source":["boston.Country.str.match('ITA')"],"execution_count":102,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      False\n","1      False\n","2      False\n","3      False\n","4      False\n","       ...  \n","995    False\n","996    False\n","997    False\n","998    False\n","999    False\n","Name: Country, Length: 1000, dtype: bool"]},"metadata":{},"execution_count":102}]},{"cell_type":"markdown","metadata":{"id":"XSI7NmH3oC2X"},"source":["Now that we have the boolean series, we can select from our dataframe."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"BrijtktxoAyw","executionInfo":{"status":"ok","timestamp":1638324482281,"user_tz":480,"elapsed":13,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"7967c820-7067-42ca-ba1b-9696777b9142"},"source":["boston.loc[boston.Country.str.match('ITA')]"],"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>56</th>\n","      <td>Boudalia, Said Sr.</td>\n","      <td>48</td>\n","      <td>M</td>\n","      <td>Belluno</td>\n","      <td>NaN</td>\n","      <td>ITA</td>\n","      <td>2:30:11</td>\n","      <td>57</td>\n","      <td>51</td>\n","      <td>2015:2016</td>\n","      <td>Boudalia</td>\n","      <td>Said Sr.</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>Achmuller, Hermann</td>\n","      <td>46</td>\n","      <td>M</td>\n","      <td>Brixen</td>\n","      <td>NaN</td>\n","      <td>ITA</td>\n","      <td>2:38:40</td>\n","      <td>157</td>\n","      <td>139</td>\n","      <td>NaN</td>\n","      <td>Achmuller</td>\n","      <td>Hermann</td>\n","    </tr>\n","    <tr>\n","      <th>792</th>\n","      <td>Consolandi, Paolo Giorgio</td>\n","      <td>39</td>\n","      <td>M</td>\n","      <td>Pessano Con Bornago (mi)</td>\n","      <td>NaN</td>\n","      <td>ITA</td>\n","      <td>2:53:29</td>\n","      <td>793</td>\n","      <td>747</td>\n","      <td>NaN</td>\n","      <td>Consolandi</td>\n","      <td>Paolo Giorgio</td>\n","    </tr>\n","    <tr>\n","      <th>922</th>\n","      <td>Zompanti, Alessandro</td>\n","      <td>48</td>\n","      <td>M</td>\n","      <td>Fiuggi Fr</td>\n","      <td>NaN</td>\n","      <td>ITA</td>\n","      <td>2:55:12</td>\n","      <td>923</td>\n","      <td>872</td>\n","      <td>NaN</td>\n","      <td>Zompanti</td>\n","      <td>Alessandro</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          Name  Age M/F  ...  Years Ran   Last Name     First Name\n","56          Boudalia, Said Sr.   48   M  ...  2015:2016    Boudalia       Said Sr.\n","156         Achmuller, Hermann   46   M  ...        NaN   Achmuller        Hermann\n","792  Consolandi, Paolo Giorgio   39   M  ...        NaN  Consolandi  Paolo Giorgio\n","922       Zompanti, Alessandro   48   M  ...        NaN    Zompanti     Alessandro\n","\n","[4 rows x 12 columns]"]},"metadata":{},"execution_count":103}]},{"cell_type":"markdown","metadata":{"id":"_JCGo1qeofVp"},"source":["In this example we relied on an *exact match*. The string pattern we passed in needed to match the queried strings exactly. However, frequently we may need to do a loose comparison or a less-restrictive search.\n","\n","For instance, what if we wanted to look up all the runner names that contain \"Will\"? How do we do that? Remember that there is no \"contains\" method in Python. Instead, we used the boolean operator `in`.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MuM5JNHSoRtZ","executionInfo":{"status":"ok","timestamp":1638324482281,"user_tz":480,"elapsed":12,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"7dd54518-659c-4e6e-861e-df02a5be4d0a"},"source":["'will' in 'williams'"],"execution_count":104,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":104}]},{"cell_type":"markdown","metadata":{"id":"SD4s1W4NpHJr"},"source":["However, Pandas has a built-in `str.contains()` method for this. It also supports regular expressions, which we'll see later.\n","\n","First, we'll create a boolean mask with the condition of containing \"will\""]},{"cell_type":"code","metadata":{"id":"d3MX1oVrpGpO","executionInfo":{"status":"ok","timestamp":1638324482415,"user_tz":480,"elapsed":140,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["wills = boston.Name.str.contains('Will')"],"execution_count":105,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xr7CpSJepTZe"},"source":["Then we'll do the classic selection!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":520},"id":"kVfuqbqbpS44","executionInfo":{"status":"ok","timestamp":1638324482417,"user_tz":480,"elapsed":6,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"e7850c7e-8bb1-4129-8abd-2d43bbb39c1d"},"source":["boston.loc[wills]"],"execution_count":106,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>93</th>\n","      <td>Vanos, William</td>\n","      <td>45</td>\n","      <td>M</td>\n","      <td>Orlando</td>\n","      <td>FL</td>\n","      <td>USA</td>\n","      <td>2:34:40</td>\n","      <td>94</td>\n","      <td>84</td>\n","      <td>NaN</td>\n","      <td>Vanos</td>\n","      <td>William</td>\n","    </tr>\n","    <tr>\n","      <th>199</th>\n","      <td>Guzick, William F</td>\n","      <td>28</td>\n","      <td>M</td>\n","      <td>Boston</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:40:43</td>\n","      <td>200</td>\n","      <td>178</td>\n","      <td>NaN</td>\n","      <td>Guzick</td>\n","      <td>William F</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>Hartje, William</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Neptune Beach</td>\n","      <td>FL</td>\n","      <td>USA</td>\n","      <td>2:46:56</td>\n","      <td>416</td>\n","      <td>386</td>\n","      <td>NaN</td>\n","      <td>Hartje</td>\n","      <td>William</td>\n","    </tr>\n","    <tr>\n","      <th>429</th>\n","      <td>Adams, William C</td>\n","      <td>33</td>\n","      <td>M</td>\n","      <td>Arlington</td>\n","      <td>VA</td>\n","      <td>USA</td>\n","      <td>2:47:15</td>\n","      <td>430</td>\n","      <td>399</td>\n","      <td>NaN</td>\n","      <td>Adams</td>\n","      <td>William C</td>\n","    </tr>\n","    <tr>\n","      <th>456</th>\n","      <td>Cunha, Will</td>\n","      <td>28</td>\n","      <td>M</td>\n","      <td>Pittsburgh</td>\n","      <td>PA</td>\n","      <td>USA</td>\n","      <td>2:47:39</td>\n","      <td>457</td>\n","      <td>424</td>\n","      <td>NaN</td>\n","      <td>Cunha</td>\n","      <td>Will</td>\n","    </tr>\n","    <tr>\n","      <th>526</th>\n","      <td>Swenson, Will</td>\n","      <td>45</td>\n","      <td>M</td>\n","      <td>Andover</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:49:10</td>\n","      <td>527</td>\n","      <td>490</td>\n","      <td>2015:2016</td>\n","      <td>Swenson</td>\n","      <td>Will</td>\n","    </tr>\n","    <tr>\n","      <th>571</th>\n","      <td>Gates, William E. Jr.</td>\n","      <td>27</td>\n","      <td>M</td>\n","      <td>Maryville</td>\n","      <td>TN</td>\n","      <td>USA</td>\n","      <td>2:49:44</td>\n","      <td>572</td>\n","      <td>534</td>\n","      <td>NaN</td>\n","      <td>Gates</td>\n","      <td>William E. Jr.</td>\n","    </tr>\n","    <tr>\n","      <th>711</th>\n","      <td>Swanson, William G</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Riverside</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:52:16</td>\n","      <td>712</td>\n","      <td>670</td>\n","      <td>NaN</td>\n","      <td>Swanson</td>\n","      <td>William G</td>\n","    </tr>\n","    <tr>\n","      <th>814</th>\n","      <td>Williamson, David</td>\n","      <td>49</td>\n","      <td>M</td>\n","      <td>Sutton</td>\n","      <td>NaN</td>\n","      <td>GBR</td>\n","      <td>2:53:46</td>\n","      <td>815</td>\n","      <td>768</td>\n","      <td>NaN</td>\n","      <td>Williamson</td>\n","      <td>David</td>\n","    </tr>\n","    <tr>\n","      <th>835</th>\n","      <td>Vargas, Will</td>\n","      <td>42</td>\n","      <td>M</td>\n","      <td>Bogota</td>\n","      <td>NaN</td>\n","      <td>COL</td>\n","      <td>2:54:07</td>\n","      <td>836</td>\n","      <td>789</td>\n","      <td>2016</td>\n","      <td>Vargas</td>\n","      <td>Will</td>\n","    </tr>\n","    <tr>\n","      <th>892</th>\n","      <td>Rivera, Will</td>\n","      <td>46</td>\n","      <td>M</td>\n","      <td>Elizabethtown</td>\n","      <td>KY</td>\n","      <td>USA</td>\n","      <td>2:54:53</td>\n","      <td>893</td>\n","      <td>843</td>\n","      <td>NaN</td>\n","      <td>Rivera</td>\n","      <td>Will</td>\n","    </tr>\n","    <tr>\n","      <th>897</th>\n","      <td>Feldman, William P.</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Greensboro</td>\n","      <td>NC</td>\n","      <td>USA</td>\n","      <td>2:54:56</td>\n","      <td>898</td>\n","      <td>848</td>\n","      <td>NaN</td>\n","      <td>Feldman</td>\n","      <td>William P.</td>\n","    </tr>\n","    <tr>\n","      <th>936</th>\n","      <td>Decamps, William M.</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Atlanta</td>\n","      <td>GA</td>\n","      <td>USA</td>\n","      <td>2:55:22</td>\n","      <td>937</td>\n","      <td>886</td>\n","      <td>NaN</td>\n","      <td>Decamps</td>\n","      <td>William M.</td>\n","    </tr>\n","    <tr>\n","      <th>939</th>\n","      <td>Versen, William R</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Minneapolis</td>\n","      <td>MN</td>\n","      <td>USA</td>\n","      <td>2:55:24</td>\n","      <td>940</td>\n","      <td>889</td>\n","      <td>NaN</td>\n","      <td>Versen</td>\n","      <td>William R</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Williamson, Jerry A</td>\n","      <td>43</td>\n","      <td>M</td>\n","      <td>Raleigh</td>\n","      <td>NC</td>\n","      <td>USA</td>\n","      <td>2:56:06</td>\n","      <td>997</td>\n","      <td>941</td>\n","      <td>2015</td>\n","      <td>Williamson</td>\n","      <td>Jerry A</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                      Name  Age M/F  ...  Years Ran   Last Name      First Name\n","93          Vanos, William   45   M  ...        NaN       Vanos         William\n","199      Guzick, William F   28   M  ...        NaN      Guzick       William F\n","415        Hartje, William   24   M  ...        NaN      Hartje         William\n","429       Adams, William C   33   M  ...        NaN       Adams       William C\n","456            Cunha, Will   28   M  ...        NaN       Cunha            Will\n","526          Swenson, Will   45   M  ...  2015:2016     Swenson            Will\n","571  Gates, William E. Jr.   27   M  ...        NaN       Gates  William E. Jr.\n","711     Swanson, William G   32   M  ...        NaN     Swanson       William G\n","814      Williamson, David   49   M  ...        NaN  Williamson           David\n","835           Vargas, Will   42   M  ...       2016      Vargas            Will\n","892           Rivera, Will   46   M  ...        NaN      Rivera            Will\n","897    Feldman, William P.   31   M  ...        NaN     Feldman      William P.\n","936    Decamps, William M.   30   M  ...        NaN     Decamps      William M.\n","939      Versen, William R   25   M  ...        NaN      Versen       William R\n","996    Williamson, Jerry A   43   M  ...       2015  Williamson         Jerry A\n","\n","[15 rows x 12 columns]"]},"metadata":{},"execution_count":106}]},{"cell_type":"markdown","metadata":{"id":"rRVNTk4EpXRF"},"source":["Damn that's a lot of Wills. Let's add in another criteria where we want to isolate the middle-aged wills, say, above the age 45. Let's create a boolean mask for this."]},{"cell_type":"code","metadata":{"id":"DvyRjgRVpWMZ","executionInfo":{"status":"ok","timestamp":1638324482417,"user_tz":480,"elapsed":5,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["forty5_plus = boston.Age >= 45"],"execution_count":107,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"WszeqYhwpj6j","executionInfo":{"status":"ok","timestamp":1638324482418,"user_tz":480,"elapsed":6,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"448a9207-bb58-4c73-fc1b-d4cae12ae11e"},"source":["boston[wills & forty5_plus]"],"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>93</th>\n","      <td>Vanos, William</td>\n","      <td>45</td>\n","      <td>M</td>\n","      <td>Orlando</td>\n","      <td>FL</td>\n","      <td>USA</td>\n","      <td>2:34:40</td>\n","      <td>94</td>\n","      <td>84</td>\n","      <td>NaN</td>\n","      <td>Vanos</td>\n","      <td>William</td>\n","    </tr>\n","    <tr>\n","      <th>526</th>\n","      <td>Swenson, Will</td>\n","      <td>45</td>\n","      <td>M</td>\n","      <td>Andover</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:49:10</td>\n","      <td>527</td>\n","      <td>490</td>\n","      <td>2015:2016</td>\n","      <td>Swenson</td>\n","      <td>Will</td>\n","    </tr>\n","    <tr>\n","      <th>814</th>\n","      <td>Williamson, David</td>\n","      <td>49</td>\n","      <td>M</td>\n","      <td>Sutton</td>\n","      <td>NaN</td>\n","      <td>GBR</td>\n","      <td>2:53:46</td>\n","      <td>815</td>\n","      <td>768</td>\n","      <td>NaN</td>\n","      <td>Williamson</td>\n","      <td>David</td>\n","    </tr>\n","    <tr>\n","      <th>892</th>\n","      <td>Rivera, Will</td>\n","      <td>46</td>\n","      <td>M</td>\n","      <td>Elizabethtown</td>\n","      <td>KY</td>\n","      <td>USA</td>\n","      <td>2:54:53</td>\n","      <td>893</td>\n","      <td>843</td>\n","      <td>NaN</td>\n","      <td>Rivera</td>\n","      <td>Will</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  Name  Age M/F  ...  Years Ran   Last Name First Name\n","93      Vanos, William   45   M  ...        NaN       Vanos    William\n","526      Swenson, Will   45   M  ...  2015:2016     Swenson       Will\n","814  Williamson, David   49   M  ...        NaN  Williamson      David\n","892       Rivera, Will   46   M  ...        NaN      Rivera       Will\n","\n","[4 rows x 12 columns]"]},"metadata":{},"execution_count":108}]},{"cell_type":"markdown","metadata":{"id":"vN3OQSy7pnwB"},"source":["Nice! We have five runners whose names contain the string \"Will\" and are over age 45. That's impressive!\n","\n","In fact, let's find out who the oldest runners are."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"63l7qE9Epm4W","executionInfo":{"status":"ok","timestamp":1638324482418,"user_tz":480,"elapsed":5,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"277de74f-2c68-4ddd-86db-6188f2a0af0c"},"source":["boston.sort_values(by = \"Age\", ascending = False)"],"execution_count":109,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>704</th>\n","      <td>Atwater, Beau</td>\n","      <td>59</td>\n","      <td>M</td>\n","      <td>Bernardsville</td>\n","      <td>NJ</td>\n","      <td>USA</td>\n","      <td>2:52:09</td>\n","      <td>705</td>\n","      <td>664</td>\n","      <td>2015:2016</td>\n","      <td>Atwater</td>\n","      <td>Beau</td>\n","    </tr>\n","    <tr>\n","      <th>648</th>\n","      <td>Duyn, Jeff H.</td>\n","      <td>57</td>\n","      <td>M</td>\n","      <td>Garrett Park</td>\n","      <td>MD</td>\n","      <td>USA</td>\n","      <td>2:51:11</td>\n","      <td>649</td>\n","      <td>609</td>\n","      <td>NaN</td>\n","      <td>Duyn</td>\n","      <td>Jeff H.</td>\n","    </tr>\n","    <tr>\n","      <th>370</th>\n","      <td>Dorval, Guy</td>\n","      <td>56</td>\n","      <td>M</td>\n","      <td>Quebec</td>\n","      <td>QC</td>\n","      <td>CAN</td>\n","      <td>2:45:53</td>\n","      <td>371</td>\n","      <td>342</td>\n","      <td>2016</td>\n","      <td>Dorval</td>\n","      <td>Guy</td>\n","    </tr>\n","    <tr>\n","      <th>326</th>\n","      <td>Fernandez, Douglas</td>\n","      <td>56</td>\n","      <td>M</td>\n","      <td>Richmond</td>\n","      <td>VA</td>\n","      <td>USA</td>\n","      <td>2:44:52</td>\n","      <td>327</td>\n","      <td>300</td>\n","      <td>NaN</td>\n","      <td>Fernandez</td>\n","      <td>Douglas</td>\n","    </tr>\n","    <tr>\n","      <th>864</th>\n","      <td>Jungkans, Chris W.</td>\n","      <td>55</td>\n","      <td>M</td>\n","      <td>Salem</td>\n","      <td>WI</td>\n","      <td>USA</td>\n","      <td>2:54:29</td>\n","      <td>865</td>\n","      <td>816</td>\n","      <td>NaN</td>\n","      <td>Jungkans</td>\n","      <td>Chris W.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>519</th>\n","      <td>Schrandt, Erik J</td>\n","      <td>20</td>\n","      <td>M</td>\n","      <td>Madison</td>\n","      <td>WI</td>\n","      <td>USA</td>\n","      <td>2:49:02</td>\n","      <td>520</td>\n","      <td>483</td>\n","      <td>NaN</td>\n","      <td>Schrandt</td>\n","      <td>Erik J</td>\n","    </tr>\n","    <tr>\n","      <th>202</th>\n","      <td>Caron, Patrick</td>\n","      <td>19</td>\n","      <td>M</td>\n","      <td>Needham</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:40:45</td>\n","      <td>203</td>\n","      <td>181</td>\n","      <td>NaN</td>\n","      <td>Caron</td>\n","      <td>Patrick</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>Mcmillan, Erik D</td>\n","      <td>19</td>\n","      <td>M</td>\n","      <td>Usaf Academy</td>\n","      <td>CO</td>\n","      <td>USA</td>\n","      <td>2:37:15</td>\n","      <td>131</td>\n","      <td>115</td>\n","      <td>NaN</td>\n","      <td>Mcmillan</td>\n","      <td>Erik D</td>\n","    </tr>\n","    <tr>\n","      <th>471</th>\n","      <td>Woodring, Seth T</td>\n","      <td>19</td>\n","      <td>M</td>\n","      <td>Fort Collins</td>\n","      <td>CO</td>\n","      <td>USA</td>\n","      <td>2:47:57</td>\n","      <td>472</td>\n","      <td>438</td>\n","      <td>NaN</td>\n","      <td>Woodring</td>\n","      <td>Seth T</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>Iwasa, Kaito</td>\n","      <td>19</td>\n","      <td>M</td>\n","      <td>Tokyo</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:27:11</td>\n","      <td>43</td>\n","      <td>39</td>\n","      <td>NaN</td>\n","      <td>Iwasa</td>\n","      <td>Kaito</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows  12 columns</p>\n","</div>"],"text/plain":["                   Name  Age M/F  ...  Years Ran  Last Name First Name\n","704       Atwater, Beau   59   M  ...  2015:2016    Atwater       Beau\n","648       Duyn, Jeff H.   57   M  ...        NaN       Duyn    Jeff H.\n","370         Dorval, Guy   56   M  ...       2016     Dorval        Guy\n","326  Fernandez, Douglas   56   M  ...        NaN  Fernandez    Douglas\n","864  Jungkans, Chris W.   55   M  ...        NaN   Jungkans   Chris W.\n","..                  ...  ...  ..  ...        ...        ...        ...\n","519    Schrandt, Erik J   20   M  ...        NaN   Schrandt     Erik J\n","202      Caron, Patrick   19   M  ...        NaN      Caron    Patrick\n","130    Mcmillan, Erik D   19   M  ...        NaN   Mcmillan     Erik D\n","471    Woodring, Seth T   19   M  ...        NaN   Woodring     Seth T\n","42         Iwasa, Kaito   19   M  ...        NaN      Iwasa      Kaito\n","\n","[1000 rows x 12 columns]"]},"metadata":{},"execution_count":109}]},{"cell_type":"markdown","metadata":{"id":"8pkhEWlnp7fk"},"source":["It looks like Beau Atwater from Bernadsville, New Jersey is running marathons in less than three hours. \n","\n","What is the age distribution of this data?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"id":"5uTOfPlap6Cj","executionInfo":{"status":"ok","timestamp":1638324482739,"user_tz":480,"elapsed":326,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"1416588d-bda6-4e86-9ebb-7a8a8acc4809"},"source":["boston.Age.hist()"],"execution_count":110,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f44689aeb10>"]},"metadata":{},"execution_count":110},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"90k4Ynj8qKiA"},"source":["It looks like most runners are clustered aroung the 20s through mid-30s, but there is a fairly long tail to the right (that is, the data is skewed to the right)."]},{"cell_type":"markdown","metadata":{"id":"zZ77ORFZoc72"},"source":["## Bonus: Parsing Indicators with `get_dummies()`"]},{"cell_type":"markdown","metadata":{"id":"m1v_D_YgooSp"},"source":["In this lecture we'll introduce a method that creates *indicator* variables out of *categorical* variables stored as text.\n","\n","Examining our `boston` dataframe, we see we have a column called \"Years Ran\". This column contains information regarding whether the runner participated in the preceding two Boston marathons (2015 and 2016)"]},{"cell_type":"code","metadata":{"id":"VlezP-dIqHwJ","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638324482740,"user_tz":480,"elapsed":4,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"c9a65aac-8ef5-4f63-92a6-2467a08ab366"},"source":["boston.head()"],"execution_count":111,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Years Ran Last Name First Name\n","0   Kirui, Geoffrey   24   M  ...       NaN     Kirui   Geoffrey\n","1       Rupp, Galen   30   M  ...       NaN      Rupp      Galen\n","2     Osako, Suguru   25   M  ...       NaN     Osako     Suguru\n","3  Biwott, Shadrack   32   M  ...       NaN    Biwott   Shadrack\n","4    Chebet, Wilson   31   M  ...      2015    Chebet     Wilson\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":111}]},{"cell_type":"markdown","metadata":{"id":"PNUiC4y5o9XY"},"source":["Let's extract all of the runners who ran in at least one of the two preceding events."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"v-iyhG0Ao1Od","executionInfo":{"status":"ok","timestamp":1638324482931,"user_tz":480,"elapsed":194,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"4945da9a-b2d6-4278-a08e-da6125c283a7"},"source":["boston[boston['Years Ran'].notnull()]"],"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>2015</td>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Keflezighi, Meb</td>\n","      <td>41</td>\n","      <td>M</td>\n","      <td>San Diego</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:17:00</td>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>2015</td>\n","      <td>Keflezighi</td>\n","      <td>Meb</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>Nyasango, Cutbert</td>\n","      <td>34</td>\n","      <td>M</td>\n","      <td>Harara</td>\n","      <td>NaN</td>\n","      <td>ZIM</td>\n","      <td>2:17:40</td>\n","      <td>14</td>\n","      <td>14</td>\n","      <td>2016</td>\n","      <td>Nyasango</td>\n","      <td>Cutbert</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>Korir, Wesley</td>\n","      <td>34</td>\n","      <td>M</td>\n","      <td>Kitale</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:18:14</td>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>2015:2016</td>\n","      <td>Korir</td>\n","      <td>Wesley</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>Maravilla, Jorge</td>\n","      <td>39</td>\n","      <td>M</td>\n","      <td>Mill Valley</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:24:27</td>\n","      <td>30</td>\n","      <td>27</td>\n","      <td>2016</td>\n","      <td>Maravilla</td>\n","      <td>Jorge</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>986</th>\n","      <td>Bretz, Virgil</td>\n","      <td>44</td>\n","      <td>M</td>\n","      <td>Mt. Kisco</td>\n","      <td>NY</td>\n","      <td>USA</td>\n","      <td>2:56:02</td>\n","      <td>987</td>\n","      <td>931</td>\n","      <td>2015:2016</td>\n","      <td>Bretz</td>\n","      <td>Virgil</td>\n","    </tr>\n","    <tr>\n","      <th>987</th>\n","      <td>Cucuzzella, Mark</td>\n","      <td>50</td>\n","      <td>M</td>\n","      <td>Shepherdstown</td>\n","      <td>WV</td>\n","      <td>USA</td>\n","      <td>2:56:03</td>\n","      <td>988</td>\n","      <td>932</td>\n","      <td>2016</td>\n","      <td>Cucuzzella</td>\n","      <td>Mark</td>\n","    </tr>\n","    <tr>\n","      <th>988</th>\n","      <td>Carron, John B</td>\n","      <td>46</td>\n","      <td>M</td>\n","      <td>Irvington</td>\n","      <td>NY</td>\n","      <td>USA</td>\n","      <td>2:56:03</td>\n","      <td>989</td>\n","      <td>933</td>\n","      <td>2016</td>\n","      <td>Carron</td>\n","      <td>John B</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Larosa, Mark</td>\n","      <td>38</td>\n","      <td>M</td>\n","      <td>North Andover</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:56:06</td>\n","      <td>996</td>\n","      <td>940</td>\n","      <td>2015:2016</td>\n","      <td>Larosa</td>\n","      <td>Mark</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Williamson, Jerry A</td>\n","      <td>43</td>\n","      <td>M</td>\n","      <td>Raleigh</td>\n","      <td>NC</td>\n","      <td>USA</td>\n","      <td>2:56:06</td>\n","      <td>997</td>\n","      <td>941</td>\n","      <td>2015</td>\n","      <td>Williamson</td>\n","      <td>Jerry A</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>315 rows  12 columns</p>\n","</div>"],"text/plain":["                    Name  Age M/F  ...  Years Ran   Last Name First Name\n","4         Chebet, Wilson   31   M  ...       2015      Chebet     Wilson\n","12       Keflezighi, Meb   41   M  ...       2015  Keflezighi        Meb\n","13     Nyasango, Cutbert   34   M  ...       2016    Nyasango    Cutbert\n","14         Korir, Wesley   34   M  ...  2015:2016       Korir     Wesley\n","29      Maravilla, Jorge   39   M  ...       2016   Maravilla      Jorge\n","..                   ...  ...  ..  ...        ...         ...        ...\n","986        Bretz, Virgil   44   M  ...  2015:2016       Bretz     Virgil\n","987     Cucuzzella, Mark   50   M  ...       2016  Cucuzzella       Mark\n","988       Carron, John B   46   M  ...       2016      Carron     John B\n","995         Larosa, Mark   38   M  ...  2015:2016      Larosa       Mark\n","996  Williamson, Jerry A   43   M  ...       2015  Williamson    Jerry A\n","\n","[315 rows x 12 columns]"]},"metadata":{},"execution_count":112}]},{"cell_type":"markdown","metadata":{"id":"PfH-qlFmpLc_"},"source":["So we have 315 runners who participated in one or both of the previous two marathons. If the runner participated in both years, the years are listed separated by a colon.\n","\n","Let's take a look at the different values that are present in the \"Years Run\" column"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qzcvqhJpG_C","executionInfo":{"status":"ok","timestamp":1638324482931,"user_tz":480,"elapsed":9,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"37efbdbd-6bba-4e9c-ebcc-d32096e929c3"},"source":["boston['Years Ran'].unique()"],"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([nan, '2015', '2016', '2015:2016'], dtype=object)"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","metadata":{"id":"kXZUa-lOpg-n"},"source":["We see here that \"Years Ran\" has one of four values:\n","1. NaN - indicating that this year (2017) is the first year that this person is participating in the marathon\n","2. 2015 - indicating that the runner also ran the 2015 marathon but not the 2016 marathon\n","3. 2016 - indicating that the runner also ran the 2016 but not the 2015 marathon\n","4. 2015:2016 - indicating that the runner ran both the 2015 and 2016 events in addition to the current 2017 event\n","\n","The non-NaN values are all categorical, stored as text. It is fine to store data this way, but it may not be the most useful for data analysis. Rather, a data analyst might split this into two separate columns called \"2015\" and \"2016\" with boolean or binary values indicating whether the runner participated in those years.\n","\n","In Pandas, it is very easy to convert these categorical variables into binary values. There is a dedicated method called `get_dummies()`, so-named because **dummy variables** are another name for indicator variables. \n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.get_dummies.html\n","\n","Let's go ahead and do this for our marathon \"Years Ran\" data. All we need to do is call `str.get_dummies()` on our \"Years Ran\" data and pass in the string separator that separates the years run."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"tXuWSsP9pfKG","executionInfo":{"status":"ok","timestamp":1638324482931,"user_tz":480,"elapsed":5,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"c363fcb6-1b7a-459a-b2b5-a2416140fd4a"},"source":["boston['Years Ran'].str.get_dummies(':')"],"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>2015</th>\n","      <th>2016</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows  2 columns</p>\n","</div>"],"text/plain":["     2015  2016\n","0       0     0\n","1       0     0\n","2       0     0\n","3       0     0\n","4       1     0\n","..    ...   ...\n","995     1     1\n","996     1     0\n","997     0     0\n","998     0     0\n","999     0     0\n","\n","[1000 rows x 2 columns]"]},"metadata":{},"execution_count":114}]},{"cell_type":"markdown","metadata":{"id":"902vsxCVsKuH"},"source":["This returns a dataframe with two separate binary columns indicating whether that row corresponds to a runner who ran in 2015, 2016, or both. This allows us to deal with numerical analysis much more cleanly.\n","\n","Let's store this dataframe as a variable that we can use later on."]},{"cell_type":"code","metadata":{"id":"O9lttrPJsNfs","executionInfo":{"status":"ok","timestamp":1638324482932,"user_tz":480,"elapsed":6,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["dummies = boston['Years Ran'].str.get_dummies(':')"],"execution_count":115,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iiUmb91mrHW5"},"source":["Unfortunately this conversion cannot be done in place. We have to manually add these new columns into our dataframes. We'll do this using the `insert()` method that we learned previously.\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.insert.html\n","\n","Where do we want to make this insertion? We need to know this so that we can tell the `insert()` method where to place the new columns. Generally speaking, it's not good practice to hard-code insertions because the indices/positions of columns and rows may change as the dataframe is modified. Instead, we'll use the `get_loc()` method on the columns array.\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.get_loc.html"]},{"cell_type":"code","metadata":{"id":"0u5HfhBprCh7","executionInfo":{"status":"ok","timestamp":1638324482932,"user_tz":480,"elapsed":6,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston.insert(loc = boston.columns.get_loc(\"Years Ran\"), column = \"Ran 2015\", value = dummies[\"2015\"])"],"execution_count":116,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"jfGFvymusqxy","executionInfo":{"status":"ok","timestamp":1638324482932,"user_tz":480,"elapsed":5,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"bb7cb13f-a0c8-4144-ccee-ad233d6353b2"},"source":["boston.head()"],"execution_count":117,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Ran 2015</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>2015</td>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Years Ran Last Name First Name\n","0   Kirui, Geoffrey   24   M  ...       NaN     Kirui   Geoffrey\n","1       Rupp, Galen   30   M  ...       NaN      Rupp      Galen\n","2     Osako, Suguru   25   M  ...       NaN     Osako     Suguru\n","3  Biwott, Shadrack   32   M  ...       NaN    Biwott   Shadrack\n","4    Chebet, Wilson   31   M  ...      2015    Chebet     Wilson\n","\n","[5 rows x 13 columns]"]},"metadata":{},"execution_count":117}]},{"cell_type":"markdown","metadata":{"id":"S8fnDuKdst0w"},"source":["Let's do the same for the year 2016."]},{"cell_type":"code","metadata":{"id":"g93gyRLhsszK","executionInfo":{"status":"ok","timestamp":1638324482932,"user_tz":480,"elapsed":5,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston.insert(loc = boston.columns.get_loc(\"Years Ran\"), column = \"Ran 2016\", value = dummies[\"2016\"])"],"execution_count":118,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"p_IEmb4Gs-iz","executionInfo":{"status":"ok","timestamp":1638324483084,"user_tz":480,"elapsed":4,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"74abcdbb-5c4a-4e4b-d843-c0dbcc49bc3f"},"source":["boston.head()"],"execution_count":119,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Ran 2015</th>\n","      <th>Ran 2016</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>M</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2015</td>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age M/F  ... Years Ran Last Name First Name\n","0   Kirui, Geoffrey   24   M  ...       NaN     Kirui   Geoffrey\n","1       Rupp, Galen   30   M  ...       NaN      Rupp      Galen\n","2     Osako, Suguru   25   M  ...       NaN     Osako     Suguru\n","3  Biwott, Shadrack   32   M  ...       NaN    Biwott   Shadrack\n","4    Chebet, Wilson   31   M  ...      2015    Chebet     Wilson\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":119}]},{"cell_type":"markdown","metadata":{"id":"c25T6L2ytI5f"},"source":["Now it is much easier to answer certain questions. For example, *Which top runners from 2017 also ran in the previous two Boston marathons?* This is easy to answer using a dual-conditional boolean statement and a selection."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"qP7tgE83s_H2","executionInfo":{"status":"ok","timestamp":1638324483085,"user_tz":480,"elapsed":5,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"cae1e38f-6eb1-41d8-9258-5ae53da3345b"},"source":["boston[(boston[\"Ran 2015\"] == 1) & (boston[\"Ran 2016\"] == 1)]"],"execution_count":120,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Ran 2015</th>\n","      <th>Ran 2016</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14</th>\n","      <td>Korir, Wesley</td>\n","      <td>34</td>\n","      <td>M</td>\n","      <td>Kitale</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:18:14</td>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Korir</td>\n","      <td>Wesley</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Ornelas, Zachary</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Ann Arbor</td>\n","      <td>MI</td>\n","      <td>USA</td>\n","      <td>2:24:40</td>\n","      <td>31</td>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Ornelas</td>\n","      <td>Zachary</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Ayr, Jason M.</td>\n","      <td>29</td>\n","      <td>M</td>\n","      <td>Allston</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:24:49</td>\n","      <td>32</td>\n","      <td>29</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Ayr</td>\n","      <td>Jason M.</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Vangampleare, Stephen</td>\n","      <td>26</td>\n","      <td>M</td>\n","      <td>Colorado Springs</td>\n","      <td>CO</td>\n","      <td>USA</td>\n","      <td>2:25:35</td>\n","      <td>37</td>\n","      <td>33</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Vangampleare</td>\n","      <td>Stephen</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>Boudalia, Said Sr.</td>\n","      <td>48</td>\n","      <td>M</td>\n","      <td>Belluno</td>\n","      <td>NaN</td>\n","      <td>ITA</td>\n","      <td>2:30:11</td>\n","      <td>57</td>\n","      <td>51</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Boudalia</td>\n","      <td>Said Sr.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>959</th>\n","      <td>Yu, Michael</td>\n","      <td>45</td>\n","      <td>M</td>\n","      <td>Zhubei City, Hsinchu County</td>\n","      <td>NaN</td>\n","      <td>TWN</td>\n","      <td>2:55:40</td>\n","      <td>960</td>\n","      <td>907</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Yu</td>\n","      <td>Michael</td>\n","    </tr>\n","    <tr>\n","      <th>962</th>\n","      <td>Husak, Tyler</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Marion</td>\n","      <td>IA</td>\n","      <td>USA</td>\n","      <td>2:55:42</td>\n","      <td>963</td>\n","      <td>910</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Husak</td>\n","      <td>Tyler</td>\n","    </tr>\n","    <tr>\n","      <th>977</th>\n","      <td>Guthals, Nathaniel</td>\n","      <td>26</td>\n","      <td>M</td>\n","      <td>Overland Park</td>\n","      <td>KS</td>\n","      <td>USA</td>\n","      <td>2:55:57</td>\n","      <td>978</td>\n","      <td>923</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Guthals</td>\n","      <td>Nathaniel</td>\n","    </tr>\n","    <tr>\n","      <th>986</th>\n","      <td>Bretz, Virgil</td>\n","      <td>44</td>\n","      <td>M</td>\n","      <td>Mt. Kisco</td>\n","      <td>NY</td>\n","      <td>USA</td>\n","      <td>2:56:02</td>\n","      <td>987</td>\n","      <td>931</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Bretz</td>\n","      <td>Virgil</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Larosa, Mark</td>\n","      <td>38</td>\n","      <td>M</td>\n","      <td>North Andover</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:56:06</td>\n","      <td>996</td>\n","      <td>940</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Larosa</td>\n","      <td>Mark</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>124 rows  14 columns</p>\n","</div>"],"text/plain":["                      Name  Age M/F  ...  Years Ran     Last Name First Name\n","14           Korir, Wesley   34   M  ...  2015:2016         Korir     Wesley\n","30        Ornelas, Zachary   25   M  ...  2015:2016       Ornelas    Zachary\n","31           Ayr, Jason M.   29   M  ...  2015:2016           Ayr   Jason M.\n","36   Vangampleare, Stephen   26   M  ...  2015:2016  Vangampleare    Stephen\n","56      Boudalia, Said Sr.   48   M  ...  2015:2016      Boudalia   Said Sr.\n","..                     ...  ...  ..  ...        ...           ...        ...\n","959            Yu, Michael   45   M  ...  2015:2016            Yu    Michael\n","962           Husak, Tyler   30   M  ...  2015:2016         Husak      Tyler\n","977     Guthals, Nathaniel   26   M  ...  2015:2016       Guthals  Nathaniel\n","986          Bretz, Virgil   44   M  ...  2015:2016         Bretz     Virgil\n","995           Larosa, Mark   38   M  ...  2015:2016        Larosa       Mark\n","\n","[124 rows x 14 columns]"]},"metadata":{},"execution_count":120}]},{"cell_type":"markdown","metadata":{"id":"cCL1_PQ-uguH"},"source":["In this particular example, the same result could be achieved by specifying the categorical value associated with runners who ran in 2015 and 2016:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"00gsr-cDumRC","executionInfo":{"status":"ok","timestamp":1638324483085,"user_tz":480,"elapsed":4,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"f15498b4-5071-4aa1-8486-ec862423e25f"},"source":["boston[boston[\"Years Ran\"] == \"2015:2016\"]"],"execution_count":121,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Ran 2015</th>\n","      <th>Ran 2016</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14</th>\n","      <td>Korir, Wesley</td>\n","      <td>34</td>\n","      <td>M</td>\n","      <td>Kitale</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:18:14</td>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Korir</td>\n","      <td>Wesley</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>Ornelas, Zachary</td>\n","      <td>25</td>\n","      <td>M</td>\n","      <td>Ann Arbor</td>\n","      <td>MI</td>\n","      <td>USA</td>\n","      <td>2:24:40</td>\n","      <td>31</td>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Ornelas</td>\n","      <td>Zachary</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>Ayr, Jason M.</td>\n","      <td>29</td>\n","      <td>M</td>\n","      <td>Allston</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:24:49</td>\n","      <td>32</td>\n","      <td>29</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Ayr</td>\n","      <td>Jason M.</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>Vangampleare, Stephen</td>\n","      <td>26</td>\n","      <td>M</td>\n","      <td>Colorado Springs</td>\n","      <td>CO</td>\n","      <td>USA</td>\n","      <td>2:25:35</td>\n","      <td>37</td>\n","      <td>33</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Vangampleare</td>\n","      <td>Stephen</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>Boudalia, Said Sr.</td>\n","      <td>48</td>\n","      <td>M</td>\n","      <td>Belluno</td>\n","      <td>NaN</td>\n","      <td>ITA</td>\n","      <td>2:30:11</td>\n","      <td>57</td>\n","      <td>51</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Boudalia</td>\n","      <td>Said Sr.</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>959</th>\n","      <td>Yu, Michael</td>\n","      <td>45</td>\n","      <td>M</td>\n","      <td>Zhubei City, Hsinchu County</td>\n","      <td>NaN</td>\n","      <td>TWN</td>\n","      <td>2:55:40</td>\n","      <td>960</td>\n","      <td>907</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Yu</td>\n","      <td>Michael</td>\n","    </tr>\n","    <tr>\n","      <th>962</th>\n","      <td>Husak, Tyler</td>\n","      <td>30</td>\n","      <td>M</td>\n","      <td>Marion</td>\n","      <td>IA</td>\n","      <td>USA</td>\n","      <td>2:55:42</td>\n","      <td>963</td>\n","      <td>910</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Husak</td>\n","      <td>Tyler</td>\n","    </tr>\n","    <tr>\n","      <th>977</th>\n","      <td>Guthals, Nathaniel</td>\n","      <td>26</td>\n","      <td>M</td>\n","      <td>Overland Park</td>\n","      <td>KS</td>\n","      <td>USA</td>\n","      <td>2:55:57</td>\n","      <td>978</td>\n","      <td>923</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Guthals</td>\n","      <td>Nathaniel</td>\n","    </tr>\n","    <tr>\n","      <th>986</th>\n","      <td>Bretz, Virgil</td>\n","      <td>44</td>\n","      <td>M</td>\n","      <td>Mt. Kisco</td>\n","      <td>NY</td>\n","      <td>USA</td>\n","      <td>2:56:02</td>\n","      <td>987</td>\n","      <td>931</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Bretz</td>\n","      <td>Virgil</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Larosa, Mark</td>\n","      <td>38</td>\n","      <td>M</td>\n","      <td>North Andover</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:56:06</td>\n","      <td>996</td>\n","      <td>940</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Larosa</td>\n","      <td>Mark</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>124 rows  14 columns</p>\n","</div>"],"text/plain":["                      Name  Age M/F  ...  Years Ran     Last Name First Name\n","14           Korir, Wesley   34   M  ...  2015:2016         Korir     Wesley\n","30        Ornelas, Zachary   25   M  ...  2015:2016       Ornelas    Zachary\n","31           Ayr, Jason M.   29   M  ...  2015:2016           Ayr   Jason M.\n","36   Vangampleare, Stephen   26   M  ...  2015:2016  Vangampleare    Stephen\n","56      Boudalia, Said Sr.   48   M  ...  2015:2016      Boudalia   Said Sr.\n","..                     ...  ...  ..  ...        ...           ...        ...\n","959            Yu, Michael   45   M  ...  2015:2016            Yu    Michael\n","962           Husak, Tyler   30   M  ...  2015:2016         Husak      Tyler\n","977     Guthals, Nathaniel   26   M  ...  2015:2016       Guthals  Nathaniel\n","986          Bretz, Virgil   44   M  ...  2015:2016         Bretz     Virgil\n","995           Larosa, Mark   38   M  ...  2015:2016        Larosa       Mark\n","\n","[124 rows x 14 columns]"]},"metadata":{},"execution_count":121}]},{"cell_type":"markdown","metadata":{"id":"GQHQDxuQtrut"},"source":["However, as we'll see, this has its disadvantages when it comes to performing certain operations on the data.\n","\n","For example, suppose we wanted to determine *How many top runners from 2017 also ran in 2015?* We can approach this using the `sum()` method."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcxWGCtitdtA","executionInfo":{"status":"ok","timestamp":1638324483258,"user_tz":480,"elapsed":177,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"00dd5ce2-9ae7-49f0-de47-c5ad70484a0d"},"source":["boston[boston[\"Ran 2015\"] == 1][\"Ran 2015\"].sum()"],"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["190"]},"metadata":{},"execution_count":122}]},{"cell_type":"markdown","metadata":{"id":"pJC15kpYuMNx"},"source":["Note that the `sum()` method works in this case because the column \"Ran 2015\" contains numerical values. It would not have worked if that column still contained string values. In that case, we would have had to rely on some awkward workaround like using `.count()`."]},{"cell_type":"markdown","metadata":{"id":"9GQcsyVz1wTW"},"source":["## Text Replacement with `replace()` and `str.replace()`"]},{"cell_type":"markdown","metadata":{"id":"w1-5D6I72IuQ"},"source":["**String replacements** are common operations that are useful for transforming, cleaning, and reshaping text data. In this lecture we'll focus on replacements with exact character sequences (regular expressions will come later).\n","\n","Let's modify our `s` string to enable more things to be done with it."]},{"cell_type":"code","metadata":{"id":"dgr5qO4Vt4Ro","executionInfo":{"status":"ok","timestamp":1638324483258,"user_tz":480,"elapsed":18,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["s += '. This section is about text.'"],"execution_count":123,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"X9HZTHKv2fxl","executionInfo":{"status":"ok","timestamp":1638324483258,"user_tz":480,"elapsed":18,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"9cef1eeb-4794-4628-a884-cfadde0063a4"},"source":["s"],"execution_count":124,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome to the text manipulation section. This section is about text.'"]},"metadata":{},"execution_count":124}]},{"cell_type":"markdown","metadata":{"id":"CcSIsre92g6b"},"source":["We've seen how replacement works. We need two parameters.\n","1. The string that we want to find and replace.\n","2. The replacement string that will be substituted in for the string that we're replacing."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"iK88-FSg2gBQ","executionInfo":{"status":"ok","timestamp":1638324483258,"user_tz":480,"elapsed":17,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"a2979ac6-e497-439b-a09f-436376ffb5ff"},"source":["s.replace('text', 'string')"],"execution_count":125,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome to the string manipulation section. This section is about string.'"]},"metadata":{},"execution_count":125}]},{"cell_type":"markdown","metadata":{"id":"LtlQFJIR2t7Q"},"source":["Notice how all instances of \"text\" have been replaced with \"string\". There's also a parameter called `max()` that limits the number of replacements made. Note that `max()` is NOT a KWARG.\n","* https://www.tutorialspoint.com/python/string_replace.htm"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VQ5mTZ_R2tN0","executionInfo":{"status":"ok","timestamp":1638324483259,"user_tz":480,"elapsed":18,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"302863bc-d699-4528-9153-8d3f63c981f0"},"source":["s.replace('text', 'string', 1)"],"execution_count":126,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Welcome to the string manipulation section. This section is about text.'"]},"metadata":{},"execution_count":126}]},{"cell_type":"markdown","metadata":{"id":"05naN2uW3IZ8"},"source":["Replacement carries over nicely to Pandas, where it has even more functionality. Let's output some random records to work with."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"WdnICqm_3Aqk","executionInfo":{"status":"ok","timestamp":1638324483259,"user_tz":480,"elapsed":17,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"83122f57-f376-490a-929c-4db782154ea5"},"source":["boston.sample(10)"],"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Ran 2015</th>\n","      <th>Ran 2016</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>14</th>\n","      <td>Korir, Wesley</td>\n","      <td>34</td>\n","      <td>M</td>\n","      <td>Kitale</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:18:14</td>\n","      <td>15</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2015:2016</td>\n","      <td>Korir</td>\n","      <td>Wesley</td>\n","    </tr>\n","    <tr>\n","      <th>328</th>\n","      <td>Montoya, Alvaro Sr.</td>\n","      <td>36</td>\n","      <td>M</td>\n","      <td>Chicago</td>\n","      <td>IL</td>\n","      <td>USA</td>\n","      <td>2:44:53</td>\n","      <td>329</td>\n","      <td>302</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2015</td>\n","      <td>Montoya</td>\n","      <td>Alvaro Sr.</td>\n","    </tr>\n","    <tr>\n","      <th>845</th>\n","      <td>Bishop, Nathan</td>\n","      <td>36</td>\n","      <td>M</td>\n","      <td>Houston</td>\n","      <td>TX</td>\n","      <td>USA</td>\n","      <td>2:54:17</td>\n","      <td>846</td>\n","      <td>797</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Bishop</td>\n","      <td>Nathan</td>\n","    </tr>\n","    <tr>\n","      <th>356</th>\n","      <td>Castillo, Franklin A. Sr.</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Doral, Florida</td>\n","      <td>NaN</td>\n","      <td>PAN</td>\n","      <td>2:45:37</td>\n","      <td>357</td>\n","      <td>330</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Castillo</td>\n","      <td>Franklin A. Sr.</td>\n","    </tr>\n","    <tr>\n","      <th>618</th>\n","      <td>Schramm, Cedric</td>\n","      <td>40</td>\n","      <td>M</td>\n","      <td>Sarreguemines</td>\n","      <td>NaN</td>\n","      <td>FRA</td>\n","      <td>2:50:43</td>\n","      <td>619</td>\n","      <td>579</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Schramm</td>\n","      <td>Cedric</td>\n","    </tr>\n","    <tr>\n","      <th>399</th>\n","      <td>Aono, Hiromasa</td>\n","      <td>35</td>\n","      <td>M</td>\n","      <td>Arlington</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:46:32</td>\n","      <td>400</td>\n","      <td>370</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Aono</td>\n","      <td>Hiromasa</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>Norcross, Robert A III</td>\n","      <td>35</td>\n","      <td>M</td>\n","      <td>Mansfield</td>\n","      <td>MA</td>\n","      <td>USA</td>\n","      <td>2:37:00</td>\n","      <td>128</td>\n","      <td>112</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2016</td>\n","      <td>Norcross</td>\n","      <td>Robert A III</td>\n","    </tr>\n","    <tr>\n","      <th>523</th>\n","      <td>Mininger, Norman H</td>\n","      <td>32</td>\n","      <td>M</td>\n","      <td>Lansing</td>\n","      <td>KS</td>\n","      <td>USA</td>\n","      <td>2:49:07</td>\n","      <td>524</td>\n","      <td>487</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2016</td>\n","      <td>Mininger</td>\n","      <td>Norman H</td>\n","    </tr>\n","    <tr>\n","      <th>860</th>\n","      <td>Nevalainen, Alec</td>\n","      <td>43</td>\n","      <td>M</td>\n","      <td>Juneau</td>\n","      <td>AK</td>\n","      <td>USA</td>\n","      <td>2:54:25</td>\n","      <td>861</td>\n","      <td>812</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2016</td>\n","      <td>Nevalainen</td>\n","      <td>Alec</td>\n","    </tr>\n","    <tr>\n","      <th>935</th>\n","      <td>Delanghe, Sean</td>\n","      <td>31</td>\n","      <td>M</td>\n","      <td>Waterloo</td>\n","      <td>ON</td>\n","      <td>CAN</td>\n","      <td>2:55:21</td>\n","      <td>936</td>\n","      <td>885</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Delanghe</td>\n","      <td>Sean</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                          Name  Age M/F  ...  Years Ran   Last Name       First Name\n","14               Korir, Wesley   34   M  ...  2015:2016       Korir           Wesley\n","328        Montoya, Alvaro Sr.   36   M  ...       2015     Montoya       Alvaro Sr.\n","845             Bishop, Nathan   36   M  ...        NaN      Bishop           Nathan\n","356  Castillo, Franklin A. Sr.   32   M  ...        NaN    Castillo  Franklin A. Sr.\n","618            Schramm, Cedric   40   M  ...        NaN     Schramm           Cedric\n","399             Aono, Hiromasa   35   M  ...        NaN        Aono         Hiromasa\n","127     Norcross, Robert A III   35   M  ...       2016    Norcross     Robert A III\n","523         Mininger, Norman H   32   M  ...       2016    Mininger         Norman H\n","860           Nevalainen, Alec   43   M  ...       2016  Nevalainen             Alec\n","935             Delanghe, Sean   31   M  ...        NaN    Delanghe             Sean\n","\n","[10 rows x 14 columns]"]},"metadata":{},"execution_count":127}]},{"cell_type":"markdown","metadata":{"id":"zBYWWznU3eqr"},"source":["Suppose we want to modify the \"M/F\" column to replace \"M\" with \"Male\" and \"F\" with \"Female\". \n","\n","One way to do this is to select the column and invoke the `str.replace()` method.\n","* https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRZnNW6u3eM2","executionInfo":{"status":"ok","timestamp":1638324483259,"user_tz":480,"elapsed":17,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"1878f4c1-c256-4795-fe84-43776006a3d0"},"source":["boston['M/F'].str.replace('F', \"Female\")"],"execution_count":128,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      M\n","1      M\n","2      M\n","3      M\n","4      M\n","      ..\n","995    M\n","996    M\n","997    M\n","998    M\n","999    M\n","Name: M/F, Length: 1000, dtype: object"]},"metadata":{},"execution_count":128}]},{"cell_type":"markdown","metadata":{"id":"-jvlIz4332cU"},"source":["It's difficult to see whether this had an effect because most of the top runners are male. Let's tag on a `value_counts()` to see if it worked."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99wDEcu13tJn","executionInfo":{"status":"ok","timestamp":1638324483259,"user_tz":480,"elapsed":12,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"1b1784af-b0c3-4dba-94ab-6d8037e14cc8"},"source":["boston['M/F'].str.replace('F', \"Female\").value_counts()"],"execution_count":129,"outputs":[{"output_type":"execute_result","data":{"text/plain":["M         944\n","Female     56\n","Name: M/F, dtype: int64"]},"metadata":{},"execution_count":129}]},{"cell_type":"markdown","metadata":{"id":"UZ_vEzRt3-G_"},"source":["Indeed it did! \n","\n","Now, what do we do about the \"M\" replacements? All we need to do is tag on another call to `str.replace()`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUw2gzSq389K","executionInfo":{"status":"ok","timestamp":1638324483417,"user_tz":480,"elapsed":167,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"630ff149-63f7-4e09-fb57-8061dab449f0"},"source":["boston['M/F'].str.replace('F', \"Female\").str.replace('M', 'Male').value_counts()"],"execution_count":130,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Male      944\n","Female     56\n","Name: M/F, dtype: int64"]},"metadata":{},"execution_count":130}]},{"cell_type":"markdown","metadata":{"id":"yWPBmvyx4SLf"},"source":["Unfortunately there is no `inplace` parameter here, so in order to save this new series into our dataframe we'll need to directly save the new column back to the dataframe."]},{"cell_type":"code","metadata":{"id":"GAmf5dRV4LHV","executionInfo":{"status":"ok","timestamp":1638324483417,"user_tz":480,"elapsed":16,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["boston['M/F'] = boston['M/F'].str.replace('F', \"Female\").str.replace('M', 'Male')"],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"dCWjaAA34cdz","executionInfo":{"status":"ok","timestamp":1638324483417,"user_tz":480,"elapsed":15,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"020c3066-e275-4d6a-db64-0fec08175764"},"source":["boston.head()"],"execution_count":132,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Age</th>\n","      <th>M/F</th>\n","      <th>City</th>\n","      <th>State</th>\n","      <th>Country</th>\n","      <th>Official Time</th>\n","      <th>Overall</th>\n","      <th>Gender</th>\n","      <th>Ran 2015</th>\n","      <th>Ran 2016</th>\n","      <th>Years Ran</th>\n","      <th>Last Name</th>\n","      <th>First Name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Kirui, Geoffrey</td>\n","      <td>24</td>\n","      <td>Male</td>\n","      <td>Keringet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:09:37</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Kirui</td>\n","      <td>Geoffrey</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Rupp, Galen</td>\n","      <td>30</td>\n","      <td>Male</td>\n","      <td>Portland</td>\n","      <td>OR</td>\n","      <td>USA</td>\n","      <td>2:09:58</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Rupp</td>\n","      <td>Galen</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Osako, Suguru</td>\n","      <td>25</td>\n","      <td>Male</td>\n","      <td>Machida-City</td>\n","      <td>NaN</td>\n","      <td>JPN</td>\n","      <td>2:10:28</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Osako</td>\n","      <td>Suguru</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Biwott, Shadrack</td>\n","      <td>32</td>\n","      <td>Male</td>\n","      <td>Mammoth Lakes</td>\n","      <td>CA</td>\n","      <td>USA</td>\n","      <td>2:12:08</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>Biwott</td>\n","      <td>Shadrack</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Chebet, Wilson</td>\n","      <td>31</td>\n","      <td>Male</td>\n","      <td>Marakwet</td>\n","      <td>NaN</td>\n","      <td>KEN</td>\n","      <td>2:12:35</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2015</td>\n","      <td>Chebet</td>\n","      <td>Wilson</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               Name  Age   M/F  ... Years Ran Last Name First Name\n","0   Kirui, Geoffrey   24  Male  ...       NaN     Kirui   Geoffrey\n","1       Rupp, Galen   30  Male  ...       NaN      Rupp      Galen\n","2     Osako, Suguru   25  Male  ...       NaN     Osako     Suguru\n","3  Biwott, Shadrack   32  Male  ...       NaN    Biwott   Shadrack\n","4    Chebet, Wilson   31  Male  ...      2015    Chebet     Wilson\n","\n","[5 rows x 14 columns]"]},"metadata":{},"execution_count":132}]},{"cell_type":"markdown","metadata":{"id":"3MckUpcy4nFM"},"source":["The Pandas version of `replace()` also supports case-sensitivity/insensitivity.\n","\n","Let's work with the \"Country\" column and replace \"USA\" with \"United States\"."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1-_buns4dCZ","executionInfo":{"status":"ok","timestamp":1638324483418,"user_tz":480,"elapsed":16,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"f5a29851-d51e-4f7d-cdcf-ece6d0adf929"},"source":["boston.Country.str.replace(\"USA\", 'United States')"],"execution_count":133,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                KEN\n","1      United States\n","2                JPN\n","3      United States\n","4                KEN\n","           ...      \n","995    United States\n","996    United States\n","997    United States\n","998    United States\n","999    United States\n","Name: Country, Length: 1000, dtype: object"]},"metadata":{},"execution_count":133}]},{"cell_type":"markdown","metadata":{"id":"Xx5vXR8Y44U0"},"source":["Simple enough. But what if we made a small type in \"USA\", for instance:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6fOw83oQ43vx","executionInfo":{"status":"ok","timestamp":1638324483418,"user_tz":480,"elapsed":12,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"e3f02a95-0a51-4b19-e6a8-0f726ae645cb"},"source":["boston.Country.str.replace(\"UsA\", 'United States')"],"execution_count":134,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0      KEN\n","1      USA\n","2      JPN\n","3      USA\n","4      KEN\n","      ... \n","995    USA\n","996    USA\n","997    USA\n","998    USA\n","999    USA\n","Name: Country, Length: 1000, dtype: object"]},"metadata":{},"execution_count":134}]},{"cell_type":"markdown","metadata":{"id":"1ToKl1PQ4_vh"},"source":["The replacement totally breaks down because the generic form of `replace()` looks for *exact* character matches. With the lower-case \"s\" in \"UsA\", there is no match.\n","\n","We can tell Pandas to be case-insensitive by setting the `case` parameter to `False`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yAXwcyuR4-vH","executionInfo":{"status":"ok","timestamp":1638324483418,"user_tz":480,"elapsed":8,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"bf11e067-c40f-45cb-e5b8-fa8f0fd7b7e5"},"source":["boston.Country.str.replace(\"UsA\", 'United States', case = False)"],"execution_count":135,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                KEN\n","1      United States\n","2                JPN\n","3      United States\n","4                KEN\n","           ...      \n","995    United States\n","996    United States\n","997    United States\n","998    United States\n","999    United States\n","Name: Country, Length: 1000, dtype: object"]},"metadata":{},"execution_count":135}]},{"cell_type":"markdown","metadata":{"id":"UStCqIZG7APm"},"source":["## An Introduction to Regular Expressions"]},{"cell_type":"markdown","metadata":{"id":"MIm5SdMK7Evi"},"source":["Regular Expressions (or regex) allow us to create patterns to search for and replace text. It is not Python-specific and can be used in any programming language that supports regex.\n","\n","We can use regex101 [regex101](https://regex101.com) as our regex playground where we'll play around with regex and become more familiar with it. This website provides a very useful regex engine as well as a quick reference guide that shows the most commonly used pattern characters.\n","\n","A few notes on regex:\n","* There are oftentimes multiple ways to create a regex pattern that will get you to a solution you want\n","* Capturing groups in regex can be referred to using numbered back-references, which can we used to recall those captured strings\n","* Anchors control word and line boundaries\n","* Sometimes it is much easier to Google regex patterns and grab one that someone has already made and is highly upvoted (e.g. on StackExchange)\n","* Regex gets a lot easier to use with practice\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eHAygnW-8UaH"},"source":["## Regex Practice in Python"]},{"cell_type":"markdown","metadata":{"id":"LYoPfj6Y8ZTs"},"source":["In this lecture, we'll explore the following topics:\n","* The `re` module in Python \n","* Regular expressions in email addresses\n","* pitfalls of regex\n","* additional resources: https://emailregex.com"]},{"cell_type":"markdown","metadata":{"id":"XwgJxxNr8tnB"},"source":["The `re` module in Python provides access to all Python regex functionality.\n","* https://docs.python.org/3/library/re.html"]},{"cell_type":"code","metadata":{"id":"AnP1xtRB5Mwu","executionInfo":{"status":"ok","timestamp":1638327860584,"user_tz":480,"elapsed":138,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["import re"],"execution_count":136,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WATrDbHN80D_"},"source":["There are several ways to use regex in Python. But perhaps the best place to start is to *define a pattern* that we want to search for.\n","\n","Let's take the example of an email address. What do we need in an email?\n","* any word character(s)\n","* any non-whitespace character(s)\n","* an @ sign\n","* another word or digit character(s)\n","* an end of line\n","\n","We've created a potential email regex on regex101.com. Let's bring it over.\n"]},{"cell_type":"code","metadata":{"id":"6lAQFkou8zs3","executionInfo":{"status":"ok","timestamp":1638328100571,"user_tz":480,"elapsed":139,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["pattern = r\"\\w\\S*@.*\\w\""],"execution_count":137,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XwWTfjDG9uzK"},"source":["Note the preceding `r` in the code, indicating that this is a raw string. This indicates that all backslashes are to be interpreted literally, and not as escapes.\n","\n","Now that we've created out pattern, we can now use the plethora of `re` methods to perform regex activities. For example, we can use `re.findall()` to obtain all non-overlapping matches of that pattern in a string."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qRjju7Q9uUK","executionInfo":{"status":"ok","timestamp":1638328213254,"user_tz":480,"elapsed":133,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"3a0352f8-95ba-4ea0-ed8e-23163b2af9f2"},"source":["re.findall(pattern, 'andy@howtopandas.com')"],"execution_count":138,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['andy@howtopandas.com']"]},"metadata":{},"execution_count":138}]},{"cell_type":"markdown","metadata":{"id":"KSqUNjDg-Kgr"},"source":["What returns is a Python list of all matches!\n","\n","What happens if we remove the characteris in front of the domain?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozWbVEDE-J23","executionInfo":{"status":"ok","timestamp":1638328250514,"user_tz":480,"elapsed":140,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"a990b86b-77b6-4ec6-d786-c6d51917f4de"},"source":["re.findall(pattern, '@howtopandas.com')"],"execution_count":139,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":139}]},{"cell_type":"markdown","metadata":{"id":"eOBNJKqX-Tdu"},"source":["We get an empty string back because our pattern no longer matches anything in the string.\n","\n","Let's try something more advanced. Some email addresses disclose the domain name but not the characters preceding it. Let's use regex to anonymize our emails so that they look like ****@gmail.com*. Here's what we'll do:\n","1. Start with an actual valid email\n","2. Capture the domain part of the email (the part we want to show)\n","3. Replace everything else besides the domain with asterisks\n","\n","Let's start with our email."]},{"cell_type":"code","metadata":{"id":"Ys5kmvqY-S9Q","executionInfo":{"status":"ok","timestamp":1638328434456,"user_tz":480,"elapsed":125,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["email = 'andy@howtopandas.com'"],"execution_count":140,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"18g2r80Z_CYM"},"source":["Now let's create a pattern (created at regex101). Remember, all we need to do is add parentheses around the part of the pattern that we want to capture into a group."]},{"cell_type":"code","metadata":{"id":"aUMl6nKn-_3a","executionInfo":{"status":"ok","timestamp":1638328540318,"user_tz":480,"elapsed":137,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["pattern = r'\\w\\S*(@.*\\w)'"],"execution_count":141,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tMHJ4s37_aE9"},"source":["Finally, we'll use `re.sub()` to make the substitution. We pass in the pattern as well as the *repl*, which is the structure that we want to replace the pattern with. Finally, we pass in the actual string that we want to assess, in this case `email`.\n","\n","What this says is the following: search `email` for the regex in `pattern`. Once found, replace the match with asterisks followed by the first captured group from the pattern."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"55Y_baWq_ZtU","executionInfo":{"status":"ok","timestamp":1638328722142,"user_tz":480,"elapsed":123,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"83d83956-c74a-4d76-be4d-fc3243153e2e"},"source":["re.sub(pattern, r'*******\\1', email)"],"execution_count":143,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'*******@howtopandas.com'"]},"metadata":{},"execution_count":143}]},{"cell_type":"markdown","metadata":{"id":"bBDpr3MyBCwh"},"source":["Let's try out this crazy regex pattern from https://emailregex.com/. Note the use of the `re.compile()` method, which compiles a regular expression pattern and returns a **pattern object** that can be used in methods like `match()` and `search()`.\n","* Compiled regular expression objects support their own methods and attributes. Refer to the Python regex page for more info: https://docs.python.org/3/library/re.html"]},{"cell_type":"code","metadata":{"id":"zeVOdogjAEfM","executionInfo":{"status":"ok","timestamp":1638329335004,"user_tz":480,"elapsed":147,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["robust_pattern = re.compile(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\", re.UNICODE)"],"execution_count":145,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LyFc9sPbCe1B"},"source":["Now let's test it. First, we'll create an invalid email address."]},{"cell_type":"code","metadata":{"id":"lGTmXJfrBdDf","executionInfo":{"status":"ok","timestamp":1638329364086,"user_tz":480,"elapsed":134,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}}},"source":["email2 = \"andy@andy@andy.com\""],"execution_count":146,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ivfp12jPCsNK"},"source":["Now let's test this email against our earlier, simplistic search pattern."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgPCpA8vCi0o","executionInfo":{"status":"ok","timestamp":1638329382604,"user_tz":480,"elapsed":141,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"fe785ba9-997c-4b47-acdc-5acc7bdd17fe"},"source":["re.findall(pattern, email2)"],"execution_count":147,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['@andy.com']"]},"metadata":{},"execution_count":147}]},{"cell_type":"markdown","metadata":{"id":"FRNuKI7oCvNF"},"source":["We see that it works! Even though the email is invalid, our simplistic search pattern nevertheless matches the ending of it.\n","\n","What about our original pattern without the capturing group?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TVxy6J9qCnUk","executionInfo":{"status":"ok","timestamp":1638329565411,"user_tz":480,"elapsed":175,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"58682a07-9ad3-4cea-c073-877d83682ce5"},"source":["re.findall(r\"\\w\\S*@.*\\w\", email2)"],"execution_count":149,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['andy@andy@andy.com']"]},"metadata":{},"execution_count":149}]},{"cell_type":"markdown","metadata":{"id":"IPYEelZFDU8F"},"source":["In that case, our entire invalid email is a match! So clearly our simplistic pattern doesn't make the cut.\n","\n","How does the robust pattern from emailregex.com do?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D42uLYGTDIwg","executionInfo":{"status":"ok","timestamp":1638329621682,"user_tz":480,"elapsed":137,"user":{"displayName":"JASON GABUNILAS","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00539107698526397852"}},"outputId":"47b37ce9-015b-4fc3-a301-5a94f7f9d851"},"source":["re.findall(robust_pattern, email2)"],"execution_count":150,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{},"execution_count":150}]},{"cell_type":"markdown","metadata":{"id":"BxHdUEmWDiP9"},"source":["The robust pattern knows that `email2` is invalid. This illustrates why it is often a better use of time to find more robust regex patterns that are already available for more complex patters, rather than making your own. The instructor recommends verifying homemade regex expressions with the community or with subject matter experts."]},{"cell_type":"code","metadata":{"id":"hSjEUs_hDhtx"},"source":[""],"execution_count":null,"outputs":[]}]}